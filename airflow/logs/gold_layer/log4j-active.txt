26/01/05 09:04:28 INFO DriverDaemon$: Started Log4j2
26/01/05 09:04:29 INFO ShutdownHookManager$: Adding shutdown hook with priority=25, defined at com.databricks.DatabricksMain.setupLog4j2Conf
26/01/05 09:04:30 INFO DriverDaemon$: SafeFailCloseBehavior is not set, using the default behavior
26/01/05 09:04:31 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey SI_KEYSTORE_PATH does not exist or is not a file: /databricks/secrets/dbts-credentials/creds.combined.pem
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey databricks.common.rpc.jetty.sslKeyStoreFile does not exist or is not a file: jetty-ssl-keystore.jks
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey databricks.monitoring.dicer.keystore does not exist or is not a file: 
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey databricks.workspaceManager.client.keystore.path does not exist or is not a file: 
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey databricks.logging.agent.keyStoreFile does not exist or is not a file: 
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey TRUSTSTORE_CA_PATH does not exist or is not a file: 
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey databricks.common.rpc.jetty.sslTrustStoreFile does not exist or is not a file: jetty-ssl-truststore.jks
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey databricks.monitoring.dicer.truststore does not exist or is not a file: 
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey databricks.workspaceManager.client.truststore.path does not exist or is not a file: 
26/01/05 09:04:31 WARN TLSConf$$anon$1: Path for configKey databricks.logging.agent.trustStoreFile does not exist or is not a file: 
26/01/05 09:04:31 INFO TLSConf$$anon$1: Using keystore path:  and truststore path: 
26/01/05 09:04:31 INFO TLSConf$$anon$1: Building TLSOptions
26/01/05 09:04:31 WARN TLSConf$$anon$1: Failed to add trust manager with RoT: Scope is not given and we can't find the current location.
26/01/05 09:04:31 WARN TLSConf$$anon$1: Failed to extract cert from :  (No such file or directory)
26/01/05 09:04:32 INFO TLSConf$$anon$1: TLSOptions Summary:
 Min TLS Version: TLS12
 Max TLS Version: TLS13
 Cipher Suites: 
 Client Auth Mode: REQUIRED
 Verification Mode: CERTIFICATE_AND_HOST_NAME_VERIFICATION
 FIPS Only: false
 Trust System Certs: false
 Trust Private Certs: false
 Fallback on No Issuers: false
 Peer Verifier: None

26/01/05 09:04:32 WARN FrameworkReadinessSource$: info service or multi readiness probe is not enabled, disabling warmup
26/01/05 09:04:32 INFO OtelSdkInitializer$: OtelSdk registered for service: driver
26/01/05 09:04:32 INFO DriverDaemon$: Current JVM Version 17.0.16
26/01/05 09:04:32 INFO DriverDaemon$: Current JVM tzdata: 2025b
26/01/05 09:04:32 INFO DriverDaemon$: Fail to access field Promise.completeAllExceptions, could be due to not using Databricks' fork
java.lang.NoSuchFieldException: scala$concurrent$impl$Promise$$completeAllExceptions
	at java.base/java.lang.Class.getDeclaredField(Class.java:2610)
	at com.databricks.DatabricksMain.getPromiseCompleteAllExceptions(DatabricksMain.scala:422)
	at com.databricks.DatabricksMain.liftedTree1$1(DatabricksMain.scala:437)
	at com.databricks.DatabricksMain.initPromiseCompleteAllExceptions(DatabricksMain.scala:435)
	at com.databricks.DatabricksMain.initDatabricks(DatabricksMain.scala:495)
	at com.databricks.DatabricksMain.$anonfun$main$1(DatabricksMain.scala:229)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.DatabricksMain.main(DatabricksMain.scala:222)
	at com.databricks.backend.daemon.driver.DriverDaemon.main(DriverDaemon.scala)
26/01/05 09:04:32 INFO ShutdownHookManager$: Adding shutdown hook with priority=100, defined at com.databricks.DatabricksMain.initDatabricks, timeout=17000ms
26/01/05 09:04:32 INFO ShutdownHookManager$: Adding shutdown hook with priority=200, defined at com.databricks.DatabricksMain.initDatabricks
26/01/05 09:04:32 INFO DriverDaemon$: ========== driver starting up ==========
26/01/05 09:04:32 INFO DriverDaemon$: Java: Azul Systems, Inc. 17.0.16
26/01/05 09:04:32 INFO DriverDaemon$: OS: Linux/aarch64 5.15.0-1097-aws
26/01/05 09:04:32 INFO DriverDaemon$: CWD: /databricks/driver
26/01/05 09:04:32 INFO DriverDaemon$: Mem: Max: 4.1G loaded GCs: PS MarkSweep, PS Scavenge
26/01/05 09:04:32 INFO DriverDaemon$: Logging multibyte characters: âœ“
26/01/05 09:04:32 INFO DriverDaemon$: 'publicFile.rolling.rewrite' appender in root logger: class org.apache.logging.log4j.core.appender.rewrite.RewriteAppender
26/01/05 09:04:32 INFO DriverDaemon$: == Modules:
26/01/05 09:04:33 INFO ZippyDataRegister$: Registered zippy data: logsCollectionPolicy
26/01/05 09:04:33 INFO ZippyListeners$: Registered zippy data update listener for logsCollectionPolicy
26/01/05 09:04:33 INFO ZippyDataStore: Initialize data key logsCollectionPolicy
26/01/05 09:04:33 INFO ZippyDataInitializer: Start initializing Zippy data keys: ArraySeq(logsCollectionPolicy), init with rest client: false, keys to load from local file: Set()
26/01/05 09:04:33 ERROR ZippyDataInitializer: Failed to init Zippy on data key: ArraySeq(logsCollectionPolicy), timeout: 600 seconds
java.lang.ExceptionInInitializerError
	at com.databricks.zippy.sdk.internal.ZippyDataInitializer.calculateInitBuckets(ZippyDataInitializer.scala:159)
	at com.databricks.zippy.sdk.internal.ZippyDataInitializer.$anonfun$initDataKeyAsync$2(ZippyDataInitializer.scala:113)
	at com.databricks.zippy.common.utils.ZippyLock.executeWithLock(ZippyLock.scala:33)
	at com.databricks.zippy.sdk.internal.ZippyDataInitializer.initDataKeyAsync(ZippyDataInitializer.scala:100)
	at com.databricks.zippy.sdk.internal.ZippyDataInitializer.$anonfun$initDataKeys$1(ZippyDataInitializer.scala:91)
	at scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)
	at scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)
	at com.databricks.zippy.sdk.internal.ZippyDataInitializer.initDataKeys(ZippyDataInitializer.scala:91)
	at com.databricks.zippy.sdk.internal.ZippyDataInitializer.initialize(ZippyDataInitializer.scala:62)
	at com.databricks.zippy.sdk.internal.ZippyDataStore.initializeIfNecessary(ZippyDataStore.scala:108)
	at com.databricks.zippy.sdk.internal.ZippyDataStore.getValueOpt(ZippyDataStore.scala:54)
	at com.databricks.zippy.sdk.interface.ZippyData.getContentOpt(ZippyData.scala:46)
	at com.databricks.logging.LogsCollectionPolicyProvider$.getLogsCollectionPolicy(LogsCollectionPolicyProvider.scala:39)
	at com.databricks.logging.UsageLogging.getLegacyArgs(UsageLogging.scala:975)
	at com.databricks.logging.UsageLogging.getLegacyArgs$(UsageLogging.scala:926)
	at com.databricks.DatabricksMain.getLegacyArgs(DatabricksMain.scala:116)
	at com.databricks.logging.UsageLogging.emitUsageLog(UsageLogging.scala:1247)
	at com.databricks.logging.UsageLogging.recordUsageWithBlobDoNotUseWeAreRemovingThis(UsageLogging.scala:1615)
	at com.databricks.logging.UsageLogging.recordUsageWithBlobDoNotUseWeAreRemovingThis$(UsageLogging.scala:1581)
	at com.databricks.DatabricksMain.recordUsageWithBlobDoNotUseWeAreRemovingThis(DatabricksMain.scala:116)
	at com.databricks.logging.UsageLogging.recordUsageWithBlobDoNotUseWeAreRemovingThis(UsageLogging.scala:832)
	at com.databricks.logging.UsageLogging.recordUsageWithBlobDoNotUseWeAreRemovingThis$(UsageLogging.scala:797)
	at com.databricks.DatabricksMain.recordUsageWithBlobDoNotUseWeAreRemovingThis(DatabricksMain.scala:116)
	at com.databricks.logging.UsageLogging.recordUsage(UsageLogging.scala:787)
	at com.databricks.logging.UsageLogging.recordUsage$(UsageLogging.scala:757)
	at com.databricks.DatabricksMain.recordUsage(DatabricksMain.scala:116)
	at com.databricks.DatabricksMain.$anonfun$startUptimeLogger$1(DatabricksMain.scala:938)
	at com.databricks.threading.NamedTimer$$anon$1.$anonfun$run$3(NamedTimer.scala:139)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.threading.NamedTimer$$anon$1.withAttributionContext(NamedTimer.scala:127)
	at com.databricks.threading.NamedTimer$$anon$1.$anonfun$run$2(NamedTimer.scala:136)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.threading.NamedTimer$$anon$1.$anonfun$run$1(NamedTimer.scala:134)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.UntrustedUtils$.tryLog(UntrustedUtils.scala:109)
	at com.databricks.threading.NamedTimer$$anon$1.run(NamedTimer.scala:134)
	at java.base/java.util.TimerThread.mainLoop(Timer.java:566)
	at java.base/java.util.TimerThread.run(Timer.java:516)
Caused by: java.lang.IllegalStateException: databricks.zippy.cloudStorage.cloudProvider must be set
	at com.databricks.zippy.cloudstorage.config.CloudStorageConf.$anonfun$cloudProvider$1(CloudStorageConf.scala:15)
	at scala.Option.getOrElse(Option.scala:201)
	at com.databricks.zippy.cloudstorage.config.CloudStorageConf.$init$(CloudStorageConf.scala:15)
	at com.databricks.zippy.cloudstorage.config.CloudStorageConf$$anon$1.<init>(CloudStorageConf.scala:63)
	at com.databricks.zippy.cloudstorage.config.CloudStorageConf$.<clinit>(CloudStorageConf.scala:63)
	... 45 more
26/01/05 09:04:33 INFO ZippyDataInitializer: Essential Zippy data initialized in : 51 ms
26/01/05 09:04:33 WARN ZippyDataStore: Failed to initialize data key logsCollectionPolicy, mark as initialized with null value
26/01/05 09:04:35 INFO DriverDaemon$: Starting prometheus metrics log export timer
26/01/05 09:04:35 WARN InfoService$: Falling back to Jetty instead of Armeria info service. Zpages will not be availableThis usually happens due to service BUILD against non-default cross-tree or older Scala versions.
26/01/05 09:04:35 INFO JettyInfoServerManager: Setting up InfoService with servlets on endpoints: (/version ,/live ,/ready ,/profile) and port:7789.
26/01/05 09:04:35 INFO log: Logging initialized @13197ms to org.eclipse.jetty.util.log.Slf4jLog
26/01/05 09:04:36 INFO Server: jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 17.0.16+8-LTS
26/01/05 09:04:36 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@46fbb0a3{/,null,AVAILABLE}
26/01/05 09:04:36 INFO AbstractConnector: Started ServerConnector@51729c2b{HTTP/1.1, (http/1.1)}{0.0.0.0:7789}
26/01/05 09:04:36 INFO Server: Started @13907ms
26/01/05 09:04:36 INFO DatabricksTraceExporter: Trace exporter starting... @ https://jaeger-collector-privileged-worker.privileged.staging.dbns.databricks.com/api/traces
26/01/05 09:04:36 INFO DatabricksTraceExporter: No exporter to unregister. Ignoring...
26/01/05 09:04:36 INFO DatabricksTraceExporter: Found value for DPP_TRACING_LOGGING_ENABLED: None
26/01/05 09:04:36 INFO log: Logging initialized @14188ms to shaded.v9_4.org.eclipse.jetty.util.log.Slf4jLog
26/01/05 09:04:36 WARN config: Weak cipher suite TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA enabled for ShadedSslContextFactory@3c06d119[provider=null,keyStore=null,trustStore=null]
26/01/05 09:04:36 WARN config: Weak cipher suite TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA enabled for ShadedSslContextFactory@3c06d119[provider=null,keyStore=null,trustStore=null]
26/01/05 09:04:37 INFO Flags: verboseExceptions: rate-limit=10 (default)
26/01/05 09:04:37 INFO Flags: useEpoll: true (default)
26/01/05 09:04:37 INFO Flags: annotatedServiceExceptionVerbosity: unhandled (default)
26/01/05 09:04:37 INFO Flags: allowSemicolonInPathComponent: true (DatabricksFlagsProvider)
26/01/05 09:04:38 INFO Flags: Using Tls engine: OpenSSL BoringSSL, 0x1010107f
26/01/05 09:04:38 INFO Flags: dumpOpenSslInfo: true (DatabricksFlagsProvider)
26/01/05 09:04:38 INFO Flags: All available SSL protocols: [SSLv2Hello, TLSv1, TLSv1.1, TLSv1.2, TLSv1.3]
26/01/05 09:04:38 INFO Flags: Default enabled SSL protocols: [TLSv1.3, TLSv1.2]
26/01/05 09:04:38 INFO Flags: All available SSL ciphers: [TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, SSL_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, SSL_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, SSL_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, SSL_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, SSL_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, SSL_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_PSK_WITH_CHACHA20_POLY1305_SHA256, SSL_ECDHE_PSK_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, SSL_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, SSL_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_PSK_WITH_AES_128_CBC_SHA, SSL_ECDHE_PSK_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, SSL_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, SSL_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_PSK_WITH_AES_256_CBC_SHA, SSL_ECDHE_PSK_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, SSL_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_256_GCM_SHA384, SSL_RSA_WITH_AES_256_GCM_SHA384, TLS_RSA_WITH_AES_128_CBC_SHA, SSL_RSA_WITH_AES_128_CBC_SHA, TLS_PSK_WITH_AES_128_CBC_SHA, SSL_PSK_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_256_CBC_SHA, SSL_RSA_WITH_AES_256_CBC_SHA, TLS_PSK_WITH_AES_256_CBC_SHA, SSL_PSK_WITH_AES_256_CBC_SHA, TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256]
26/01/05 09:04:38 INFO Flags: Default enabled SSL ciphers: [TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256, TLS_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256]
26/01/05 09:04:38 INFO SystemInfo: IPv6: disabled (no IPv6 network interface)
26/01/05 09:04:39 WARN SslContextUtil: Attempted to configure TLS with a bad cipher suite (TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA). Do not use any cipher suites listed in https://datatracker.ietf.org/doc/html/rfc7540#appendix-A
26/01/05 09:04:39 INFO JaegerHttpsExporter: Exporting Spans to unauthenticated https://jaeger-collector-privileged-worker.privileged.staging.dbns.databricks.com/api/traces?format=jaeger.thrift
26/01/05 09:04:39 INFO DatabricksTraceExporter: Trace exporter started... @ https://jaeger-collector-privileged-worker.privileged.staging.dbns.databricks.com/api/traces for service driver
26/01/05 09:04:39 INFO ReplDaemon$: Using REPL daemon
26/01/05 09:04:40 INFO SnapstartUtils$: Checkpoint host network info: CheckpointHostInfo(10.152.169.53,ip-10-152-169-53,10.152.169.53,ip-10-152-169-53/10.152.169.53,node.host.local)
26/01/05 09:04:40 INFO DriverDaemonRoutingServer$: Starting DriverDaemonRoutingServer....
26/01/05 09:04:40 WARN UnaryRpcServiceBuilder: Ignoring a duplicate JettyRPC endpoint: JettyRpcRoute(GET,class com.databricks.api.proto.chauffeur.GetStartupInfo). Only the first mapping will be used instead to route the requests coming on this path.
26/01/05 09:04:40 WARN UnaryRpcServiceBuilder: Ignoring a duplicate JettyRPC endpoint: JettyRpcRoute(POST,class com.databricks.api.proto.chauffeur.GetStartupInfo). Only the first mapping will be used instead to route the requests coming on this path.
26/01/05 09:04:40 WARN UnaryRpcServiceBuilder: Ignoring a duplicate JettyRPC endpoint: JettyRpcRoute(DELETE,class com.databricks.api.proto.chauffeur.GetStartupInfo). Only the first mapping will be used instead to route the requests coming on this path.
26/01/05 09:04:40 WARN UnaryRpcServiceBuilder: Ignoring a duplicate JettyRPC endpoint: JettyRpcRoute(PATCH,class com.databricks.api.proto.chauffeur.GetStartupInfo). Only the first mapping will be used instead to route the requests coming on this path.
26/01/05 09:04:40 WARN UnaryRpcServiceBuilder: Ignoring a duplicate JettyRPC endpoint: JettyRpcRoute(PUT,class com.databricks.api.proto.chauffeur.GetStartupInfo). Only the first mapping will be used instead to route the requests coming on this path.
26/01/05 09:04:41 INFO ArmeriaSslConfigurer$: Using these TLS settings for Armeria server listening on :6061
 mTLS enabled: true
 protocols: 
 ciphers: 

26/01/05 09:04:41 INFO DatabricksServerBuilder: Setting server max connection age to 3600000 ms
26/01/05 09:04:41 INFO DatabricksServerBuilder: Set http2MaxStreamsPerConnection to 100
26/01/05 09:04:41 INFO DatabricksServerBuilder: Adaptive Admission Control is disabled, using static request limits: maxConcurrentRequests: 100, maxPendingRequests: None.
26/01/05 09:04:41 INFO SystemInfo: hostname: ip-10-152-169-53 (from /proc/sys/kernel/hostname)
26/01/05 09:04:41 WARN ExecutorServiceMetrics: Failed to bind as com.databricks.threading.InstrumentedScheduledThreadPoolExecutor is unsupported.
26/01/05 09:04:41 INFO DatabricksServerBuilder: Armeria UnaryRpcService server is created:
framework: ARMERIA
port: 6061
rpc_services {
  backend_type: UNARY_RPC_SERVICE
  service_name: "com.databricks.backend.daemon.driver.DriverDaemonCompatRoutingServerBackend"
  grpc_service: "databricks.chauffeur.DriverClusterInfoService"
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetStartupInfo"
    grpc_method: "GetStartupInfo"
  }
}
rpc_services {
  backend_type: UNARY_RPC_SERVICE
  service_name: "com.databricks.backend.daemon.driver.DriverDaemonCompatRoutingServerBackend"
  grpc_service: "databricks.chauffeur.DriverCorralService"
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.AutoCompleteInternalRequest"
    grpc_method: "AutoCompleteInternal"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetRuntimeServiceVersionsInternalRequest"
    grpc_method: "GetRuntimeServiceVersionsInternal"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.WorkersPendingRemoval"
    grpc_method: "WorkersPendingRemoval"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.SyncShortTermMemory"
    grpc_method: "SyncShortTermMemory"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.ListRunningExecutors"
    grpc_method: "ListRunningExecutors"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.InstallLibrariesOnExecutionContext"
    grpc_method: "InstallLibrariesOnExecutionContext"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetDriverExecutionStatusRequest"
    grpc_method: "GetDriverExecutionStatus"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.ListNodesRequest"
    grpc_method: "ListNodes"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetClusterLoadInfo"
    grpc_method: "GetClusterLoadInfo"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.StopReplRequest"
    grpc_method: "StopRepl"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetAutoscalingInfoInternalRequest"
    grpc_method: "GetAutoscalingInfo"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.AreQueriesAlive"
    grpc_method: "AreQueriesAlive"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GracefulDecommissionWorkersInPods"
    grpc_method: "GracefulDecommissionWorkersInPods"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetStartupInfo"
    grpc_method: "GetStartupInfo"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.ListSqlGatewayCommands"
    grpc_method: "ListSqlGatewayCommands"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetWorkloadRuntimeInfo"
    grpc_method: "GetWorkloadRuntimeInfo"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetInstallLibrariesOnExecutionContextStatus"
    grpc_method: "GetInstallLibrariesOnExecutionContextStatus"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.ServerlessOverspendExtensionRequest"
    grpc_method: "ServerlessOverspendExtension"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.tracing.ToggleServiceTracing"
    grpc_method: "ToggleServiceTracing"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.InputReplyInternalRequest"
    grpc_method: "InputReplyInternal"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetUsageInfo"
    grpc_method: "GetUsageInfo"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.CancelCommandRequest"
    grpc_method: "CancelCommand"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.SubscribeToLiveQuery"
    grpc_method: "SubscribeToLiveQuery"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.AttachLibrariesRequest"
    grpc_method: "AttachLibraries"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.ExecuteCommandRequest"
    grpc_method: "ExecuteCommand"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.InspectInternalRequest"
    grpc_method: "InspectInternal"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetEnvironmentStatus"
    grpc_method: "GetEnvironmentStatus"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.ReplayWorkloadRequest"
    grpc_method: "ReplayWorkload"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.driver.webterminal.GetWebTerminalConfig"
    grpc_method: "GetWebTerminalConfig"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetDriverHealthRequest"
    grpc_method: "GetDriverHealth"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.SetAdmissionStatus"
    grpc_method: "SetAdmissionStatus"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetSparkActiveJobInfoRequest"
    grpc_method: "GetSparkActiveJobInfo"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.StartReplWarmupRequest"
    grpc_method: "StartReplWarmup"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.StartReplRequest"
    grpc_method: "StartRepl"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.SnapshotReplsRequest"
    grpc_method: "SnapshotRepls"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.WriteDbfsCommandResultInternalRequest"
    grpc_method: "WriteDbfsCommandResultInternal"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.TerminateServerlessSparkSession"
    grpc_method: "TerminateServerlessSparkSession"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.libraries.GetAllLibraryStatusesRequest"
    grpc_method: "GetAllLibraryStatuses"
  }
  handlers {
    jetty_request_type: "com.databricks.api.proto.chauffeur.GetReplStatusRequest"
    grpc_method: "GetReplStatus"
  }
}
concurrency_conf {
  num_threads: 50
  max_concurrent_requests: 100
}
connection_conf {
  max_connection_age_ms: 3600000
}
request_conf {
  timeout_ms: 3600000
  max_request_body_size_bytes: 1073741824
}
framework_version: "1.30.3-r0"
max_header_list_size_bytes: 98304

26/01/05 09:04:41 INFO NetstatUtil$: netstat -lnpt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 192.168.200.30:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8082          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8083          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8081          0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4318            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4316            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4317            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4315            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.4:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.6:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:6000            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.40:9878     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.40:9877     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.10:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.10:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.154:53          0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.28:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.28:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7778            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7769            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7898            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8686            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8687            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.5:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:19001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10002         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10002         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.3:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9878          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9877          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9491          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9491          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9666          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9313          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9410          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9410          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9202          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9202          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9206          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9206          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9205          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9205          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8953          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8910          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:53            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:443          0.0.0.0:*               LISTEN      -                   
tcp6       0      0 :::12306                :::*                    LISTEN      -                   
tcp6       0      0 :::5051                 :::*                    LISTEN      -                   
tcp6       0      0 :::22001                :::*                    LISTEN      -                   
tcp6       0      0 :::6060                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::6059                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7078                 :::*                    LISTEN      -                   
tcp6       0      0 :::7079                 :::*                    LISTEN      -                   
tcp6       0      0 :::7076                 :::*                    LISTEN      -                   
tcp6       0      0 :::7075                 :::*                    LISTEN      -                   
tcp6       0      0 :::7070                 :::*                    LISTEN      -                   
tcp6       0      0 :::7071                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7069                 :::*                    LISTEN      -                   
tcp6       0      0 :::7945                 :::*                    LISTEN      -                   
tcp6       0      0 :::8002                 :::*                    LISTEN      -                   
tcp6       0      0 :::8003                 :::*                    LISTEN      -                   
tcp6       0      0 :::8000                 :::*                    LISTEN      -                   
tcp6       0      0 :::8001                 :::*                    LISTEN      -                   
tcp6       0      0 :::8085                 :::*                    LISTEN      -                   
tcp6       0      0 :::7776                 :::*                    LISTEN      -                   
tcp6       0      0 :::7777                 :::*                    LISTEN      -                   
tcp6       0      0 :::7788                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7789                 :::*                    LISTEN      1502/java           
tcp6       0      0 ::1:8953                :::*                    LISTEN      -                   
tcp6       0      0 127.0.0.1:4052          :::*                    LISTEN      -                   
tcp6       0      0 :::111                  :::*                    LISTEN      -                   
tcp6       0      0 :::9082                 :::*                    LISTEN      -                   
tcp6       0      0 :::9080                 :::*                    LISTEN      -                   
tcp6       0      0 :::9081                 :::*                    LISTEN      -                   
tcp6       0      0 :::9095                 :::*                    LISTEN      -                   
tcp6       0      0 :::9100                 :::*                    LISTEN      -                   
tcp6       0      0 :::1015                 :::*                    LISTEN      -                   
tcp6       0      0 :::1021                 :::*                    LISTEN      -                   
tcp6       0      0 :::8934                 :::*                    LISTEN      -                   
tcp6       0      0 :::8900                 :::*                    LISTEN      -                   
tcp6       0      0 :::9515                 :::*                    LISTEN      -                   
tcp6       0      0 :::1453                 :::*                    LISTEN      -                   
tcp6       0      0 :::9292                 :::*                    LISTEN      -                   
tcp6       0      0 :::9998                 :::*                    LISTEN      -                   
tcp6       0      0 :::9863                 :::*                    LISTEN      -                   
tcp6       0      0 :::10255                :::*                    LISTEN      -                   
tcp6       0      0 :::19094                :::*                    LISTEN      -                   
tcp6       0      0 :::19095                :::*                    LISTEN      -                   
tcp6       0      0 :::19093                :::*                    LISTEN      -                   
tcp6       0      0 :::19090                :::*                    LISTEN      -                   
tcp6       0      0 :::19096                :::*                    LISTEN      -                   

26/01/05 09:04:41 INFO Server: Serving HTTP at /[0:0:0:0:0:0:0:0]:6061 - http://127.0.0.1:6061/
26/01/05 09:04:41 INFO DriverDaemonRoutingServer$: Successfully started DriverDaemonRoutingServer!
26/01/05 09:04:41 INFO ReplDaemon$: creating ReplDaemon
26/01/05 09:04:41 INFO ReplDaemon: Creating driver corral backend
26/01/05 09:04:41 INFO NetstatUtil$: netstat -lnpt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 192.168.200.30:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8082          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8083          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8081          0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4318            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4316            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4317            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4315            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.4:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.6:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:6000            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.40:9878     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.40:9877     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.10:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.10:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.154:53          0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.28:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.28:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7778            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7769            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7898            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8686            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8687            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.5:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:19001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10002         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10002         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.3:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9878          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9877          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9491          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9491          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9666          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9313          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9410          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9410          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9202          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9202          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9206          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9206          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9205          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9205          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8953          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8910          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:53            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:443          0.0.0.0:*               LISTEN      -                   
tcp6       0      0 :::12306                :::*                    LISTEN      -                   
tcp6       0      0 :::5051                 :::*                    LISTEN      -                   
tcp6       0      0 :::22001                :::*                    LISTEN      -                   
tcp6       0      0 :::6060                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::6061                 :::*                    LISTEN      1502/java           
tcp6       0      0 :::6059                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7078                 :::*                    LISTEN      -                   
tcp6       0      0 :::7079                 :::*                    LISTEN      -                   
tcp6       0      0 :::7076                 :::*                    LISTEN      -                   
tcp6       0      0 :::7075                 :::*                    LISTEN      -                   
tcp6       0      0 :::7070                 :::*                    LISTEN      -                   
tcp6       0      0 :::7071                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7069                 :::*                    LISTEN      -                   
tcp6       0      0 :::7945                 :::*                    LISTEN      -                   
tcp6       0      0 :::8002                 :::*                    LISTEN      -                   
tcp6       0      0 :::8003                 :::*                    LISTEN      -                   
tcp6       0      0 :::8000                 :::*                    LISTEN      -                   
tcp6       0      0 :::8001                 :::*                    LISTEN      -                   
tcp6       0      0 :::8085                 :::*                    LISTEN      -                   
tcp6       0      0 :::7776                 :::*                    LISTEN      -                   
tcp6       0      0 :::7777                 :::*                    LISTEN      -                   
tcp6       0      0 :::7788                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7789                 :::*                    LISTEN      1502/java           
tcp6       0      0 ::1:8953                :::*                    LISTEN      -                   
tcp6       0      0 127.0.0.1:4052          :::*                    LISTEN      -                   
tcp6       0      0 :::111                  :::*                    LISTEN      -                   
tcp6       0      0 :::9082                 :::*                    LISTEN      -                   
tcp6       0      0 :::9080                 :::*                    LISTEN      -                   
tcp6       0      0 :::9081                 :::*                    LISTEN      -                   
tcp6       0      0 :::9095                 :::*                    LISTEN      -                   
tcp6       0      0 :::9100                 :::*                    LISTEN      -                   
tcp6       0      0 :::1015                 :::*                    LISTEN      -                   
tcp6       0      0 :::1021                 :::*                    LISTEN      -                   
tcp6       0      0 :::8934                 :::*                    LISTEN      -                   
tcp6       0      0 :::8900                 :::*                    LISTEN      -                   
tcp6       0      0 :::9515                 :::*                    LISTEN      -                   
tcp6       0      0 :::1453                 :::*                    LISTEN      -                   
tcp6       0      0 :::9292                 :::*                    LISTEN      -                   
tcp6       0      0 :::9998                 :::*                    LISTEN      -                   
tcp6       0      0 :::9863                 :::*                    LISTEN      -                   
tcp6       0      0 :::10255                :::*                    LISTEN      -                   
tcp6       0      0 :::19094                :::*                    LISTEN      -                   
tcp6       0      0 :::19095                :::*                    LISTEN      -                   
tcp6       0      0 :::19093                :::*                    LISTEN      -                   
tcp6       0      0 :::19090                :::*                    LISTEN      -                   
tcp6       0      0 :::19096                :::*                    LISTEN      -                   

26/01/05 09:04:42 INFO DriverCorral: Creating the sparkConf
26/01/05 09:04:42 WARN SparkConfUtils$: Setting the same key twice for spark.databricks.io.directoryCommit.enableLogicalDelete
26/01/05 09:04:42 WARN SparkConfUtils$: Setting the same key twice for spark.hadoop.hive.server2.keystore.path
26/01/05 09:04:42 INFO SparkConfUtils$: Customize spark config according to file /tmp/custom-spark.conf
26/01/05 09:04:42 INFO SecurityModeConfUtils$: Unsetting warmup security mode confs
26/01/05 09:04:42 INFO DatabricksILoop$: Skipped applying cluster scope dynamic spark confs in warm-up mode
26/01/05 09:04:42 INFO DriverCorral: Created the sparkConf
26/01/05 09:04:42 INFO DriverCorral: Creating the driver context
26/01/05 09:04:42 INFO DatabricksILoop$: Class Server Dir: /local_disk0/tmp/repl/spark-4430798447037324317-fd45f081-9ff9-4bf0-affe-5ebab56ad4c7
26/01/05 09:04:42 INFO DatabricksEdgeConfigs: serverlessEnabled : true
26/01/05 09:04:42 INFO DatabricksEdgeConfigs: perfPackEnabled : false
26/01/05 09:04:42 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
26/01/05 09:04:43 INFO DatabricksEdgeConfigs: spark.databricks.test.default.enabled : false
26/01/05 09:04:43 INFO SparkContext: Running Spark version 4.0.0
26/01/05 09:04:43 INFO SparkContext: OS info Linux, 5.15.0-1097-aws, aarch64
26/01/05 09:04:43 INFO SparkContext: Java version 17.0.16+8-LTS
26/01/05 09:04:43 INFO ResourceUtils: ==============================================================
26/01/05 09:04:43 INFO ResourceUtils: No custom resources configured for spark.driver.
26/01/05 09:04:43 INFO ResourceUtils: ==============================================================
26/01/05 09:04:43 INFO SparkContext: Submitted application: Databricks Shell
26/01/05 09:04:44 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
26/01/05 09:04:44 INFO SecurityManager: Changing view acls to: root
26/01/05 09:04:44 INFO SecurityManager: Changing modify acls to: root
26/01/05 09:04:44 INFO SecurityManager: Changing view acls groups to: root
26/01/05 09:04:44 INFO SecurityManager: Changing modify acls groups to: root
26/01/05 09:04:44 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL enabled: false
26/01/05 09:04:44 WARN SnapstartLocalManagerImpl: SnapstartLocalManagerFacadeImpl is not available.
26/01/05 09:04:44 INFO Utils: Successfully started service 'sparkDriver' on port 39833.
26/01/05 09:04:44 INFO SparkEnv: Registering MapOutputTracker
26/01/05 09:04:44 INFO SparkEnv: Registering BlockManagerMaster
26/01/05 09:04:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
26/01/05 09:04:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
26/01/05 09:04:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
26/01/05 09:04:44 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-973b5b1e-e5c8-4a23-8754-f5e30cfc3490
26/01/05 09:04:45 INFO SparkEnv: Registering OutputCommitCoordinator
26/01/05 09:04:45 INFO ThreadDumpManager: ThreadDumpManager: started.
26/01/05 09:04:45 INFO HangingThreadDetector: HangingThreadDetector starting.
26/01/05 09:04:45 INFO SparkContext: Spark configuration:
databricks.data.unity.enabled=true
libraryDownload.sleepIntervalSeconds=5
libraryDownload.timeoutSeconds=180
spark.aether.driver.id=driver
spark.akka.frameSize=256
spark.app.name=Databricks Shell
spark.app.startTime=1767603883139
spark.cleaner.referenceTracking.blocking=false
spark.databricks.abTesting.client.httpClientClass=com.databricks.common.client.DreamcatcherRuntimeHttpClient
spark.databricks.acl.checkPermission.impl=com.databricks.sql.acl.CheckPermissions
spark.databricks.acl.client=com.databricks.spark.sql.acl.client.SparkSqlAclClient
spark.databricks.acl.defaultSessionCatalogOnly=true
spark.databricks.acl.dfAclsEnabled=true
spark.databricks.acl.enabled=true
spark.databricks.acl.filesystem.checkPermission.impl=com.databricks.sql.acl.CheckFileSystemSafety
spark.databricks.acl.hiveNamespaceOnly=true
spark.databricks.acl.provider=com.databricks.sql.acl.ReflectionBackedAclProvider
spark.databricks.acl.scim.client=com.databricks.spark.sql.acl.client.DriverToWebappScimClient
spark.databricks.acl.secureCatalogRestrictObjLists=true
spark.databricks.acl.secureDefaultSessionCatalogImpls=com.databricks.sql.transaction.tahoe.catalog.DeltaCatalog
spark.databricks.acl.skipCheckingPlans=NONE
spark.databricks.automl.serviceEnabled=true
spark.databricks.autotune.maintenance.client.classname=com.databricks.maintenanceautocompute.MACClientImpl
spark.databricks.cloudProvider=AWS
spark.databricks.cloudfetch.hasRegionSupport=true
spark.databricks.cloudfetch.requestDownloadUrlsWithHeaders=*********(redacted)
spark.databricks.cloudfetch.requesterClassName=*********(redacted)
spark.databricks.cluster.profile=singleNode
spark.databricks.clusterSource=REPL
spark.databricks.clusterUsageTags.autoTerminationMinutes=0
spark.databricks.clusterUsageTags.clusterAvailability=ONDEMAND
spark.databricks.clusterUsageTags.clusterCreator=ReplLauncher
spark.databricks.clusterUsageTags.clusterK8sClusterUUID=0fc285cd-1ace-428d-b1a8-22e4de67009c
spark.databricks.clusterUsageTags.clusterLocalSsdCounts=0
spark.databricks.clusterUsageTags.clusterNodeType=m7g.2xlarge
spark.databricks.clusterUsageTags.clusterOwnerOrgId=-1
spark.databricks.clusterUsageTags.clusterType=ondemand
spark.databricks.clusterUsageTags.clusterUnityCatalogMode=SHARED
spark.databricks.clusterUsageTags.dataPlaneRegion=us-east-2
spark.databricks.clusterUsageTags.dbrClusterDataplaneRegion=us-east-2
spark.databricks.clusterUsageTags.driverNodeType=m7g.xlarge
spark.databricks.clusterUsageTags.enableElasticDisk=false
spark.databricks.clusterUsageTags.executorPodPoolEnabled=false
spark.databricks.clusterUsageTags.isColdStart=false
spark.databricks.clusterUsageTags.isDbletNode=true
spark.databricks.clusterUsageTags.isNephos=true
spark.databricks.clusterUsageTags.isServerlessAutoscalingEnabled=false
spark.databricks.clusterUsageTags.k8sClusterType=dblet
spark.databricks.clusterUsageTags.nephosClusterPerformanceTarget=PERFORMANCE_OPTIMIZED
spark.databricks.clusterUsageTags.nephosUseDbrClusterPoolController=true
spark.databricks.clusterUsageTags.nephosWorkloadType=REPL
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Abfss=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Dbfs=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2File=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Gcs=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2S3=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Volumes=0
spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Workspace=0
spark.databricks.clusterUsageTags.onInstancePool=false
spark.databricks.clusterUsageTags.orgId=-1
spark.databricks.clusterUsageTags.region=us-east-2
spark.databricks.clusterUsageTags.serverlessIsShield=false
spark.databricks.clusterUsageTags.serverlessPlatformChannel=unspecified
spark.databricks.clusterUsageTags.sparkImageLabel=release__client.4.x-snapshot-aarch64-scala2.13__databricks__client.4.8-rc2__f393c10__a32e9ba__jenkins__a09785f__format-3
spark.databricks.clusterUsageTags.sparkVersion=client.4.8-aarch64-scala2.13
spark.databricks.clusterUsageTags.virtualDriverInstanceType=serverless-driver-4cpu-low-mem-graviton-aws
spark.databricks.clusterUsageTags.virtualExecutorInstanceType=serverless-executor-32mem-graviton-aws
spark.databricks.clusterUsageTags.workerEnvironmentId=aioa
spark.databricks.cmv1.fuseOnHostEnabled=false
spark.databricks.credential.aws.secretKey.redactor=*********(redacted)
spark.databricks.credential.redactor=*********(redacted)
spark.databricks.credential.scope.fs.adls.gen2.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.gs.auth.access.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.impl=*********(redacted)
spark.databricks.credential.scope.fs.onelake.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.r2.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.s3a.tokenProviderClassName=*********(redacted)
spark.databricks.credential.scope.fs.wasbs.tokenProviderClassName=*********(redacted)
spark.databricks.daemon.driver.disableInternalMetastoreCertCheck=false
spark.databricks.dataPlaneRegion=us-east-2
spark.databricks.dbfsFusePrivaceraIntegration=false
spark.databricks.delta.logStore.crossCloud.fatal=true
spark.databricks.delta.multiClusterWrites.enabled=true
spark.databricks.deltaSharing.clientClassName=com.databricks.deltasharing.DataSharingClientImpl
spark.databricks.driver.cleanUpSparkSessionsOnUCSharedClusters=false
spark.databricks.driver.coldStartFallbackTimeout=65
spark.databricks.driver.dynamicSparkConfs.clusterScope.enabled=false
spark.databricks.driver.enableDncOomMessage=true
spark.databricks.driver.jediCachePrewarmEnabled=true
spark.databricks.driver.jediCachePrewarmLibraryList=asyncio,botocore,ipywidgets,numpy,py4j,pyarrow,pyspark,pyspark.ml,pyspark.sql,sklearn,spark
spark.databricks.driver.jediCachePrewarmTimeout=60
spark.databricks.driver.pythonReplWarmpoolSize=2
spark.databricks.driver.remoteSparkQueryProgress.enabled=true
spark.databricks.driver.serverless.wsfsAsyncFlushEnabled=true
spark.databricks.driver.serverless.wsfsPidNamespaceIdRegistration=false
spark.databricks.driver.startupPythonReplEnabled=false
spark.databricks.driverNfs.clusterWidePythonLibsEnabled=true
spark.databricks.driverNfs.enabled=true
spark.databricks.driverNfs.pathSuffix=.ephemeral_nfs
spark.databricks.driverNodeTypeId=m7g.xlarge
spark.databricks.enablePublicDbfsFuse=false
spark.databricks.environmentCache.enabled=true
spark.databricks.eventLog.dir=eventlogs
spark.databricks.eventLog.enabled=true
spark.databricks.eventLog.listenerClassName=com.databricks.backend.daemon.driver.DBCEventLoggingListener
spark.databricks.filesystem.lokiOverDbfs.enabled=true
spark.databricks.hadoop.disableLocalFileSystem=true
spark.databricks.hive.acl.checkPermission.impl=com.databricks.sql.acl.HiveCheckPermissions
spark.databricks.hive.acl.filesystem.checkPermission.impl=com.databricks.sql.acl.HiveCheckFileSystemSafety
spark.databricks.io.cache.enabled=true
spark.databricks.io.cache.guaranteedDiskUtilization=0.0
spark.databricks.io.cache.maxDiskUsage=214748364800
spark.databricks.io.cache.minDiskAvailable=54760833024
spark.databricks.io.directoryCommit.enableLogicalDelete=false
spark.databricks.isShieldWorkspace=false
spark.databricks.lakehouseMonitoring.clientClassName=com.databricks.datamonitoring.clients.MonitorClientImpl
spark.databricks.managedCatalog.clientClassName=com.databricks.managedcatalog.ManagedCatalogClientImpl
spark.databricks.metrics.filesystem_io_metrics=true
spark.databricks.overrideDefaultCommitProtocol=org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol
spark.databricks.passthrough.adls.gen2.tokenProviderClassName=*********(redacted)
spark.databricks.passthrough.adls.tokenProviderClassName=*********(redacted)
spark.databricks.passthrough.enabled=false
spark.databricks.passthrough.glue.credentialsProviderFactoryClassName=*********(redacted)
spark.databricks.passthrough.glue.executorServiceFactoryClassName=*********(redacted)
spark.databricks.passthrough.oauth.refresher.impl=*********(redacted)
spark.databricks.passthrough.s3a.threadPoolExecutor.factory.class=com.databricks.backend.daemon.driver.aws.S3APassthroughThreadPoolExecutorFactory
spark.databricks.passthrough.s3a.tokenProviderClassName=*********(redacted)
spark.databricks.preemption.enabled=true
spark.databricks.proxyHadoopTraffic.host=192.168.200.20
spark.databricks.proxyHadoopTraffic.port=80
spark.databricks.pyspark.enableIptables=true
spark.databricks.pyspark.enableProcessIsolation=true
spark.databricks.pyspark.enablePy4JSecurity=true
spark.databricks.pyspark.iptable.outbound.whitelisted.ports=80
spark.databricks.pyspark.py4jConfRedaction.enabled=true
spark.databricks.pyspark.pythonUdfsOnly=true
spark.databricks.pyspark.runAsLowPrivilegeUser=*********(redacted)
spark.databricks.pyspark.setupFSPermisionsDuringClusterWarmup=true
spark.databricks.pyspark.trustedFilesystems=com.databricks.adl.AdlFileSystem,com.databricks.s3a.S3AFileSystem,shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystem,shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystemHadoop3,shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem,shaded.databricks.v20180920_b33d810.org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem,shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem,shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystemHadoop3,shaded.databricks.V2_1_4.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem,shaded.databricks.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem,shaded.databricks.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemHadoop3,com.databricks.sql.io.LokiFileSystem,com.databricks.common.filesystem.LokiS3FS,com.databricks.common.filesystem.LokiABFS,com.databricks.common.filesystem.LokiSecureABFS,com.databricks.common.filesystem.LokiGCFS,org.apache.spark.sql.execution.datasources.jdbc.JdbcFileSystem
spark.databricks.python.spark.connect.enabled=true
spark.databricks.python.spark.connect.useMtlsProxy=true
spark.databricks.redactor=com.databricks.spark.util.DatabricksSparkLogRedactorProxy
spark.databricks.repl.autoreload.reliability.enabled=true
spark.databricks.repl.dataflow.enabled=false
spark.databricks.repl.enableClassFileCleanup=true
spark.databricks.repl.pythonDeveloperMode.allowed=false
spark.databricks.repl.pythonInterruptInstrumentation.maxExplicitInterruptCatchCount=3
spark.databricks.repl.pythonInterruptInstrumentation.maxImplicitInterruptCatchCount=1
spark.databricks.repl.sqlMagic.usePy4j=true
spark.databricks.safespark.externalUDF.env.installerObjectName=com.databricks.backend.daemon.driver.UDFEnvUtils
spark.databricks.scala.serverless.enabled=true
spark.databricks.secret.envVar.keys.toRedact=*********(redacted)
spark.databricks.secret.sparkConf.keys.toRedact=*********(redacted)
spark.databricks.serverless.internal.useWarmPathSecret=*********(redacted)
spark.databricks.service.dbutils.repl.backend=com.databricks.dbconnect.ReplDBUtils
spark.databricks.service.dbutils.server.backend=com.databricks.dbconnect.SparkServerDBUtils
spark.databricks.session.share=false
spark.databricks.singleuser.fuse.scala.enabled=*********(redacted)
spark.databricks.sparkConnectEnvSync.enabled=true
spark.databricks.sparkContextId=4430798447037324317
spark.databricks.sql.configMapperClass=com.databricks.dbsql.config.SqlConfigMapperBridge
spark.databricks.sql.enforceAnsiMode.enabled=true
spark.databricks.streaming.enforceAllowlistOnSharedCluster=true
spark.databricks.tahoe.logStore.aws.class=com.databricks.tahoe.store.MultiClusterLogStore
spark.databricks.tahoe.logStore.azure.class=com.databricks.tahoe.store.AzureLogStore
spark.databricks.tahoe.logStore.class=com.databricks.tahoe.store.DelegatingLogStore
spark.databricks.tahoe.logStore.gcp.class=com.databricks.tahoe.store.GCPLogStore
spark.databricks.tahoe.logStore.r2.class=com.databricks.tahoe.store.R2LogStore
spark.databricks.thriftserver.ssl.ciphers.exclude=^.*_(MD5|SHA1)$,^TLS_RSA_.*$, ^SSL_.*$, ^.*_NULL_.*$, ^.*_anon_.*$
spark.databricks.ui.logViewingEnabled=false
spark.databricks.unityCatalog.clientClassName=com.databricks.managedcatalog.ManagedCatalogClientImpl
spark.databricks.unityCatalog.credentialManager.apiTokenProviderClassName=*********(redacted)
spark.databricks.unityCatalog.credentialManager.tokenRefreshEnabled=*********(redacted)
spark.databricks.unityCatalog.enableLibrariesApiOnSharedCluster=false
spark.databricks.unityCatalog.enableServiceCredentials=*********(redacted)
spark.databricks.unityCatalog.enabled=true
spark.databricks.unityCatalog.enforce.permissions=true
spark.databricks.unityCatalog.externalLocationFallbackMode.enabled=false
spark.databricks.unityCatalog.fabricCrawler.enabled=false
spark.databricks.unityCatalog.glue.federation.enabled=true
spark.databricks.unityCatalog.hms.federation.enableDbfsSupport=true
spark.databricks.unityCatalog.hms.federation.enabled=true
spark.databricks.unityCatalog.lakehouseFederation.writes.enabled=true
spark.databricks.unityCatalog.legacy.enableCrossScopeCredCache=true
spark.databricks.unityCatalog.pathGovernance.dbfsOverUc.enabled=false
spark.databricks.unityCatalog.queryFederation.enabled=true
spark.databricks.unityCatalog.userIsolation.python.enabled=*********(redacted)
spark.databricks.unityCatalog.userIsolation.scala.enabled=*********(redacted)
spark.databricks.unityCatalog.volumes.enabled=true
spark.databricks.unityCatalog.volumes.fuse.server.enabled=true
spark.databricks.unityCatalog.warmupEnabled=false
spark.databricks.unityCatalog.warmupRealClientEnabled=false
spark.databricks.universe.commandContextFactory.class=com.databricks.spark.util.UniverseCommandContextFactoryImpl
spark.databricks.workerNodeTypeId=serverless-executor-32mem-graviton-aws
spark.databricks.wsfs.workspaceNotebookCwd=true
spark.databricks.wsfs.workspacePrivatePreview=true
spark.databricks.wsfsPublicPreview=true
spark.delta.sharing.profile.provider.class=*********(redacted)
spark.deploy.appRegistrationCheckEnabled=true
spark.driver.allowMultipleContexts=false
spark.driver.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED
spark.driver.host=10.152.169.53
spark.driver.maxResultSize=4g
spark.driver.port=39833
spark.driver.tempDirectory=/local_disk0/tmp
spark.eventLog.enabled=false
spark.excludeOnFailure.application.fetchFailure.enabled=false
spark.executor.extraClassPath=/databricks/hadoop-safety-jars/*:/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/*
spark.executor.extraJavaOptions=-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED -Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -Xlog:gc,gc+heap=info,gc+metaspace=info:stdout:time,uptime,level,tags -Xss4m -Djava.library.path=/usr/java/packages/lib/aarch64:/lib:/usr/lib:/usr/lib/aarch64-linux-gnu/jni:/lib/aarch64-linux-gnu:/usr/lib/aarch64-linux-gnu:/usr/lib/jni:/databricks/native -Dcom.datalogics.PDFL.JavaSDK.resourcePath=/databricks/apdfl/Resources -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dio.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -XX:+UseBiasedLocking -XX:+IgnoreUnrecognizedVMOptions --add-modules=jdk.incubator.vector --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal.consumer=ALL-UNNAMED --add-opens=jdk.jfr/jdk.jfr.internal=ALL-UNNAMED --add-opens=java.management/sun.management=ALL-UNNAMED --add-opens=java.base/jdk.internal.loader=ALL-UNNAMED --add-opens=jdk.naming.dns/com.sun.jndi.dns=java.naming -Djdk.reflect.useDirectMethodHandle=false -Dio.netty.tryReflectionSetAccessible=true -Djava.security.manager=allow --enable-native-access=ALL-UNNAMED -XX:StartFlightRecording=duration=1s,filename=/dev/null -XX:+UseParallelGC -Ddatabricks.serviceName=spark-executor-1
spark.executor.id=driver
spark.executor.memory=5773m
spark.executor.tempDirectory=/local_disk0/tmp
spark.extraListeners=com.databricks.backend.daemon.driver.DBCEventLoggingListener
spark.files.fetchFailure.unRegisterOutputOnHost=true
spark.files.overwrite=true
spark.files.useFetchCache=false
spark.hadoop.databricks.dbfs.client.version=v2
spark.hadoop.databricks.fs.perfMetrics.enable=true
spark.hadoop.databricks.fs.s3a.dmk.slowPathSampler.class=com.databricks.unity.DBRUCSHandleWrapper
spark.hadoop.databricks.fs.s3a.dmk.slowPathSampling.probability.double=0.005
spark.hadoop.databricks.loki.fileStatusCache.enabled=true
spark.hadoop.databricks.loki.fileSystemCache.enabled=true
spark.hadoop.databricks.s3.create.deleteUnnecessaryFakeDirectories=false
spark.hadoop.databricks.s3.verifyBucketExists.enabled=false
spark.hadoop.databricks.s3commit.client.sslTrustAll=false
spark.hadoop.fs.AbstractFileSystem.gs.impl=shaded.databricks.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS
spark.hadoop.fs.abfs.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.abfs.impl.disable.cache=true
spark.hadoop.fs.abfss.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.abfss.impl.disable.cache=true
spark.hadoop.fs.adl.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.adl.impl.disable.cache=true
spark.hadoop.fs.azure.authorization.caching.enable=false
spark.hadoop.fs.azure.cache.invalidator.type=com.databricks.encryption.utils.CacheInvalidatorImpl
spark.hadoop.fs.azure.skip.metrics=true
spark.hadoop.fs.azure.user.agent.prefix=*********(redacted)
spark.hadoop.fs.cpfs-abfss.impl=*********(redacted)
spark.hadoop.fs.cpfs-abfss.impl.disable.cache=true
spark.hadoop.fs.cpfs-adl.impl=*********(redacted)
spark.hadoop.fs.cpfs-adl.impl.disable.cache=true
spark.hadoop.fs.cpfs-s3.impl=*********(redacted)
spark.hadoop.fs.cpfs-s3a.impl=*********(redacted)
spark.hadoop.fs.cpfs-s3n.impl=*********(redacted)
spark.hadoop.fs.dbfs.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.dbfs.impl.disable.cache=true
spark.hadoop.fs.dbfsartifacts.impl=com.databricks.backend.daemon.data.client.DBFSV1
spark.hadoop.fs.fcfs-abfs.impl=*********(redacted)
spark.hadoop.fs.fcfs-abfs.impl.disable.cache=true
spark.hadoop.fs.fcfs-abfss.impl=*********(redacted)
spark.hadoop.fs.fcfs-abfss.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3a.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3a.impl.disable.cache=true
spark.hadoop.fs.fcfs-s3n.impl=*********(redacted)
spark.hadoop.fs.fcfs-s3n.impl.disable.cache=true
spark.hadoop.fs.fcfs-wasb.impl=*********(redacted)
spark.hadoop.fs.fcfs-wasb.impl.disable.cache=true
spark.hadoop.fs.fcfs-wasbs.impl=*********(redacted)
spark.hadoop.fs.fcfs-wasbs.impl.disable.cache=true
spark.hadoop.fs.file.impl=com.databricks.backend.daemon.driver.WorkspaceLocalFileSystem
spark.hadoop.fs.gs.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.gs.impl.disable.cache=true
spark.hadoop.fs.gs.outputstream.upload.chunk.size=16777216
spark.hadoop.fs.idbfs.impl=com.databricks.io.idbfs.IdbfsFileSystem
spark.hadoop.fs.local-file.impl=com.databricks.backend.daemon.driver.WorkspaceLocalFileSystem
spark.hadoop.fs.mlflowdbfs.impl=com.databricks.mlflowdbfs.MlflowdbfsFileSystem
spark.hadoop.fs.r2.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.r2.impl.disable.cache=true
spark.hadoop.fs.s3.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.s3.impl.disable.cache=true
spark.hadoop.fs.s3a.assumed.role.credentials.provider=*********(redacted)
spark.hadoop.fs.s3a.attempts.maximum=10
spark.hadoop.fs.s3a.block.size=67108864
spark.hadoop.fs.s3a.connection.maximum=200
spark.hadoop.fs.s3a.connection.timeout=50000
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.fast.upload.active.blocks=32
spark.hadoop.fs.s3a.fast.upload.default=true
spark.hadoop.fs.s3a.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.s3a.impl.disable.cache=true
spark.hadoop.fs.s3a.max.total.tasks=1000
spark.hadoop.fs.s3a.multipart.size=10485760
spark.hadoop.fs.s3a.multipart.threshold=104857600
spark.hadoop.fs.s3a.retry.interval=250ms
spark.hadoop.fs.s3a.retry.limit=6
spark.hadoop.fs.s3a.retry.throttle.interval=500ms
spark.hadoop.fs.s3a.threads.max=136
spark.hadoop.fs.s3a.vectored.read.max.merged.size=2M
spark.hadoop.fs.s3a.vectored.read.min.seek.size=128K
spark.hadoop.fs.s3n.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.s3n.impl.disable.cache=true
spark.hadoop.fs.stage.impl=com.databricks.backend.daemon.driver.managedcatalog.PersonalStagingFileSystem
spark.hadoop.fs.stage.impl.disable.cache=true
spark.hadoop.fs.wasb.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.wasb.impl.disable.cache=true
spark.hadoop.fs.wasbs.impl=com.databricks.sql.io.LokiFileSystem
spark.hadoop.fs.wasbs.impl.disable.cache=true
spark.hadoop.hive.hmshandler.retry.attempts=10
spark.hadoop.hive.hmshandler.retry.interval=2000
spark.hadoop.hive.server2.enable.doAs=false
spark.hadoop.hive.server2.idle.operation.timeout=7200000
spark.hadoop.hive.server2.idle.session.timeout=900000
spark.hadoop.hive.server2.keystore.password=*********(redacted)
spark.hadoop.hive.server2.keystore.path=/databricks/keys/jetty-ssl-driver-keystore.jks
spark.hadoop.hive.server2.session.check.interval=60000
spark.hadoop.hive.server2.thrift.bind.host=127.0.0.1
spark.hadoop.hive.server2.thrift.http.cookie.auth.enabled=false
spark.hadoop.hive.server2.thrift.http.port=10000
spark.hadoop.hive.server2.transport.mode=http
spark.hadoop.hive.server2.use.SSL=false
spark.hadoop.hive.warehouse.subdir.inherit.perms=false
spark.hadoop.mapred.output.committer.class=com.databricks.backend.daemon.data.client.DirectOutputCommitter
spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2
spark.hadoop.parquet.abfs.readahead.optimization.enabled=true
spark.hadoop.parquet.block.size.row.check.max=10
spark.hadoop.parquet.block.size.row.check.min=10
spark.hadoop.parquet.filter.columnindex.enabled=false
spark.hadoop.parquet.memory.pool.ratio=0.5
spark.hadoop.parquet.page.metadata.validation.enabled=true
spark.hadoop.parquet.page.size.check.estimate=false
spark.hadoop.parquet.page.verify-checksum.enabled=true
spark.hadoop.parquet.page.write-checksum.enabled=true
spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.enabled=false
spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.throwsException=false
spark.hadoop.spark.databricks.metrics.filesystem_metrics=true
spark.hadoop.spark.driverproxy.customHeadersToProperties=*********(redacted)
spark.hadoop.spark.hadoop.aws.glue.cache.db.size=1000
spark.hadoop.spark.hadoop.aws.glue.cache.db.ttl-mins=30
spark.hadoop.spark.hadoop.aws.glue.cache.table.size=1000
spark.hadoop.spark.hadoop.aws.glue.cache.table.ttl-mins=30
spark.hadoop.spark.sql.parquet.output.committer.class=org.apache.spark.sql.parquet.DirectParquetOutputCommitter
spark.hadoop.spark.sql.sources.outputCommitterClass=com.databricks.backend.daemon.data.client.MapReduceDirectOutputCommitter
spark.home=/databricks/spark
spark.logConf=true
spark.master=local[*, 4]
spark.memory.offHeap.enabled=true
spark.memory.offHeap.size=16012804096
spark.metrics.conf=/databricks/spark/conf/metrics.properties
spark.r.backendConnectionTimeout=604800
spark.r.numRBackendThreads=1
spark.rdd.compress=true
spark.repl.class.outputDir=/local_disk0/tmp/repl/spark-4430798447037324317-fd45f081-9ff9-4bf0-affe-5ebab56ad4c7
spark.rpc.message.maxSize=256
spark.scheduler.listenerbus.eventqueue.capacity=20000
spark.scheduler.mode=FAIR
spark.serializer.objectStreamReset=100
spark.shuffle.manager=SORT
spark.shuffle.memoryFraction=0.2
spark.shuffle.reduceLocality.enabled=false
spark.shuffle.service.enabled=true
spark.shuffle.service.port=4048
spark.sparklyr-backend.threads=1
spark.sparkr.use.daemon=false
spark.speculation=false
spark.speculation.multiplier=3
spark.speculation.quantile=0.9
spark.sql.allowMultipleContexts=false
spark.sql.ansi.enabled=true
spark.sql.hive.convertCTAS=true
spark.sql.hive.convertMetastoreParquet=true
spark.sql.hive.metastore.jars=/databricks/databricks-hive/*
spark.sql.hive.metastore.sharedPrefixes=org.mariadb.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,microsoft.sql.DateTimeOffset,microsoft.sql.Types,com.databricks,com.codahale,com.fasterxml.jackson,shaded.databricks
spark.sql.hive.metastore.version=0.13.0
spark.sql.hive.useDatabricksHive122=true
spark.sql.legacy.createHiveTableByDefault=false
spark.sql.parquet.cacheMetadata=true
spark.sql.parquet.compression.codec=snappy
spark.sql.sources.commitProtocolClass=com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol
spark.sql.sources.default=delta
spark.sql.streaming.checkpointFileManagerClass=com.databricks.spark.sql.streaming.DatabricksCheckpointFileManager
spark.sql.streaming.stopTimeout=15s
spark.sql.warehouse.dir=*********(redacted)
spark.storage.blockManagerTimeoutIntervalMs=300000
spark.storage.memoryFraction=0.5
spark.streaming.driver.writeAheadLog.allowBatching=true
spark.streaming.driver.writeAheadLog.closeFileAfterWrite=true
spark.task.reaper.enabled=true
spark.task.reaper.killTimeout=60s
spark.ui.killEnabled=false
spark.ui.port=41616
spark.ui.prometheus.enabled=true
spark.worker.aioaLazyConfig.dbfsReadinessCheckClientClass=com.databricks.backend.daemon.driver.NephosDbfsReadinessCheckClient
spark.worker.aioaLazyConfig.iamReadinessCheckClientClass=com.databricks.backend.daemon.driver.NephosIamRoleCheckClient
spark.worker.cleanup.enabled=false
spark.worker.register.initialRegistrationIntervalSec=20
spark.worker.register.initialRegistrationRetries=20
spark.worker.register.proLongedRegistrationRetries=20
spark.worker.register.prolongedRegistrationIntervalSec=10
26/01/05 09:04:45 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3a. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3n. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfs. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfss. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme gs. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme r2. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme wasb. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme wasbs. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:45 ERROR SparkHadoopUtil: No filesystem implementation found for sharepoint scheme.
26/01/05 09:04:45 ERROR SparkHadoopUtil: No filesystem implementation found for gdrive scheme.
26/01/05 09:04:45 INFO JettyUtils: Start Jetty 10.152.169.53:41616 for SparkUI
26/01/05 09:04:45 INFO Server: jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 17.0.16+8-LTS
26/01/05 09:04:45 INFO Server: Started @23018ms
26/01/05 09:04:45 INFO AbstractConnector: Started ServerConnector@62f5d1ea{HTTP/1.1, (http/1.1)}{10.152.169.53:41616}
26/01/05 09:04:45 INFO Utils: Successfully started service 'SparkUI' on port 41616.
26/01/05 09:04:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c36c11e{/,null,AVAILABLE,@Spark}
26/01/05 09:04:45 INFO DbrActivityRecorder: FrameProfilerExporter is disabled.
26/01/05 09:04:46 INFO Utils: Successfully started service 'org.apache.spark.sql.connect.service.SparkConnectService' on port 15002.
26/01/05 09:04:46 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
26/01/05 09:04:46 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
26/01/05 09:04:47 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:04:46 +0000] "GET /metrics HTTP/1.1" 200 49994 
26/01/05 09:04:47 INFO ErrorEventListener: Configured monitoring unexpected Java module errors with a throttling threshold of 5 unique events per 10 minutes
26/01/05 09:04:47 INFO JfrStreamingManager: Started JFR stream JDK17 HMR
26/01/05 09:04:47 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
26/01/05 09:04:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 5773, script: , vendor: , offHeap -> name: offHeap, amount: 15271, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
26/01/05 09:04:47 INFO ResourceProfile: Limiting resource is cpu
26/01/05 09:04:47 INFO ResourceProfileManager: Added ResourceProfile id: 0
26/01/05 09:04:47 INFO SecurityManager: Changing view acls to: root
26/01/05 09:04:47 INFO SecurityManager: Changing modify acls to: root
26/01/05 09:04:47 INFO SecurityManager: Changing view acls groups to: root
26/01/05 09:04:47 INFO SecurityManager: Changing modify acls groups to: root
26/01/05 09:04:47 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL enabled: false
26/01/05 09:04:47 INFO UnifiedMemoryManager: Unmanaged memory polling started with interval 1000ms
26/01/05 09:04:47 INFO FairSchedulableBuilder: Fair scheduler configuration not found, created default pool: default, schedulingMode: FAIR, minShare: 0, weight: 1
26/01/05 09:04:47 INFO DAGScheduler: Initialized stage-level aggregated metrics cache: maxSize=200, ttlMinutes=5 (currently caching QueryProfile aggregated metrics only)
26/01/05 09:04:47 INFO Executor: Starting executor ID driver on host node.host.local
26/01/05 09:04:47 INFO Executor: OS info Linux, 5.15.0-1097-aws, aarch64
26/01/05 09:04:47 INFO Executor: Java version 17.0.16+8-LTS
26/01/05 09:04:47 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): 'file:/databricks/hadoop-safety-jars/*,file:/databricks/spark/dbconf/log4j/executor/,file:/databricks/spark/dbconf/jets3t/,file:/databricks/spark/dbconf/hadoop/,file:/databricks/hive/conf/,file:/databricks/jars/*,file:/databricks/driver/conf/,file:/databricks/driver/hadoop,file:/databricks/driver/executor,file:/databricks/driver/*,file:/databricks/driver/jets3t'
26/01/05 09:04:47 INFO Executor: Using REPL class URI: spark://10.152.169.53:39833/classes
26/01/05 09:04:47 INFO Executor: Created or updated repl class loader org.apache.spark.executor.ExecutorClassLoader@4ae48059 for default.
26/01/05 09:04:47 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
26/01/05 09:04:47 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
26/01/05 09:04:48 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
26/01/05 09:04:48 INFO TaskSchedulerImpl: Task preemption enabled.
26/01/05 09:04:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38387.
26/01/05 09:04:49 INFO NettyBlockTransferService: Server created on 10.152.169.53:38387
26/01/05 09:04:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
26/01/05 09:04:49 INFO BlockManager: external shuffle service port = 4048
26/01/05 09:04:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.152.169.53, 38387, None)
26/01/05 09:04:49 INFO BlockManagerMasterEndpoint: Registering block manager 10.152.169.53:38387 with 17.0 GiB RAM, BlockManagerId(driver, 10.152.169.53, 38387, None)
26/01/05 09:04:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.152.169.53, 38387, None)
26/01/05 09:04:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.152.169.53, 38387, None)
26/01/05 09:04:49 INFO Server: jetty-9.4.58.v20250814; built: 2025-08-14T02:28:49.637Z; git: 8f1440587e9e4ae7db3d74cf205643f3d707148d; jvm 17.0.16+8-LTS
26/01/05 09:04:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@61c5ce95{/,null,AVAILABLE}
26/01/05 09:04:49 INFO SslContextFactory: x509=X509@653b4d21(1,h=[driver-proxy, dbr-admission-webhook-svc.databricks.svc, dbr-driver-pod-pool.serverless.svc.cluster.local, dbr-driver-pod-pool],a=[],w=[]) for Server@4db40d05[provider=null,keyStore=file:///databricks/keys/jetty_ssl_driver_keystore.jks,trustStore=file:///databricks/keys/jetty_ssl_driver_keystore.jks]
26/01/05 09:04:49 INFO AbstractConnector: Started ServerConnector@6f4d995a{SSL, (ssl, http/1.1)}{0.0.0.0:1023}
26/01/05 09:04:49 INFO Server: Started @27104ms
26/01/05 09:04:49 INFO FuseDaemonServer: FuseDaemonServer started on 1023 with endpoint: '/get-unity-token'.
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3a. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme s3n. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfs. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme abfss. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme gs. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme r2. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme wasb. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 INFO SparkHadoopUtil: Installing CredentialsScopeFilesystem for scheme wasbs. Previous value: com.databricks.sql.io.LokiFileSystem
26/01/05 09:04:51 ERROR SparkHadoopUtil: No filesystem implementation found for sharepoint scheme.
26/01/05 09:04:51 ERROR SparkHadoopUtil: No filesystem implementation found for gdrive scheme.
26/01/05 09:04:51 INFO MetricsSystem: Starting driver MetricsSystem
26/01/05 09:04:51 INFO DBCEventLoggingListener: Initializing DBCEventLoggingListener (compressionEnabled=true)
26/01/05 09:04:51 INFO DBCEventLoggingListener: Logging events to eventlogs/4430798447037324317/eventlog
26/01/05 09:04:51 INFO SparkContext: Registered listener com.databricks.backend.daemon.driver.DBCEventLoggingListener
26/01/05 09:04:51 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@2c36c11e{/,null,STOPPED,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79851013{/jobs,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@cf7146{/jobs/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@40b4fec9{/jobs/job,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@356824fb{/jobs/job/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3ec6bfbf{/stages,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3ac17b50{/stages/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5334bb35{/stages/stage,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3517e6a4{/stages/stage/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@752eeec{/stages/pool,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7c334dec{/stages/pool/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5501d9cb{/stages/taskThreadDump,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@18315379{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25a7e7fe{/storage,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1058d778{/storage/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@693972a9{/storage/rdd,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a5f067c{/storage/rdd/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34dfec02{/executors,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4ddc78ec{/executors/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1ba61bc8{/executors/threadDump,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2de5d619{/executors/threadDump/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44371c54{/executors/heapHistogram,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@42985696{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@708a2978{/executors/heapHistogram,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41f4534f{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@76a9337c{/static,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20465588{/,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@48a7bd07{/api,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@408be22c{/metrics,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@60d501f6{/jobs/job/kill,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@435876cf{/stages/stage/kill,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@76d5040d{/connect,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@9be847b{/connect/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@52936640{/connect/session,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25052fcc{/connect/session/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3dd570c3{/metrics/json,null,AVAILABLE,@Spark}
26/01/05 09:04:51 INFO DatabricksILoop$: Successfully registered spark metrics in Prometheus registry
26/01/05 09:04:51 INFO DatabricksILoop$: Successfully initialized SparkContext
26/01/05 09:04:55 INFO LibraryResolutionManager: Preferred maven central mirror is configured to https://maven-central.storage-download.googleapis.com/maven2/
26/01/05 09:04:55 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-burst. Using default: 100000000000
26/01/05 09:04:55 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-steady-rate. Using default: 6000000000
26/01/05 09:04:55 INFO OutgoingDirectNotebookBufferRateLimiter: OutgoingDirectNotebookBufferRateLimiter initialized with clusterBurst=100000000000, clusterSteadyRate=6000000000 
26/01/05 09:04:55 WARN OutgoingDirectNotebookBufferRateLimiter$: No value specified for db-outgoing-buffer-throttler-warning-interval-sec. Using default: 60
26/01/05 09:04:55 INFO DriverCorral: Created the driver context
26/01/05 09:04:56 INFO NonBlockingCircuitBreaker: name:DBFS-SHARED state:CLOSED
26/01/05 09:04:57 INFO DriverCorral: metastoreType: UnknownMetastore, enableMetastoreHealthCheck: false
26/01/05 09:04:57 INFO ColdStartReplFactory: REPL pool is disabled.
26/01/05 09:04:57 INFO ReplDaemon: Created driver corral backend
26/01/05 09:04:57 INFO ReplDaemon$: Transitioning REPL Daemon state: EMPTY_STATE ==> WARMUP_STARTED
26/01/05 09:04:57 INFO ReplDaemon$: REPL Daemon warmup has started.
26/01/05 09:04:57 INFO ReplDaemon$: Attempting to run: 'Kill all orphaned Scala kernel JVMs at driver startup'
26/01/05 09:04:57 INFO PreloadClasses$: Preloading classes from file: /databricks/driver/preload_class.lst.repl
26/01/05 09:05:07 INFO PreloadClasses$: ClassNotFoundException while preloading 26 classes from /databricks/driver/preload_class.lst.repl: com.databricks.common.http.WebMetricsRecorder$,com.databricks.rpc.InternalServerState$,com.databricks.backend.daemon.data.client.UserContextUtils$,com.databricks.sql.DatabricksSQLConf$GlobalTaskSamplePercent,com.databricks.logging.LogsCollectionPolicyFetcher$LogTopic$USAGE_LOG$,com.databricks.backend.daemon.driver.JupyterClient$shellLock$,com.databricks.backend.daemon.driver.DriverCorral$SessionUserCreationException,com.databricks.logging.structured.DataSourceUtil$,com.databricks.backend.daemon.driver.WSFSDriverManager$,com.databricks.sql.kinesis.ReadKinesisAnalysis,org.apache.spark.sql.kafka010.ReadKafkaAnalysis,com.databricks.sql.pulsar.ReadPulsarAnalysis,com.databricks.api.proto.datadaemon.AuditableForDataDaemonProtoRpc,org.apache.spark.storage.NoopRpcEndpointRef,com.databricks.logging.LogsCollectionPolicyFetcher$LogTopic$STRUCTURED_LOG$,com.databricks.backend.daemon.driver.JupyterClient$messageSigner$,com.databricks.logging.proto.catalog.SupportedDataSource,com.databricks.backend.daemon.driver.JupyterClient$controlLock$,com.databricks.logging.proto.catalog.SupportedDataSource$,dbshaded.opentelemetry.io.opentelemetry.sdk.metrics.internal.exemplar.ExemplarFilter,com.databricks.spark.snapstart.core.SnapstartLocalManagerFacadeImpl$,com.databricks.sql.DatabricksSQLConf$SoakingTaskSamplePercent,com.databricks.api.proto.datadaemon.CustomAuditFormatForDataDaemonProtoRpc,com.databricks.logging.LogsCollectionPolicyFetcher$LogTopic,com.databricks.backend.daemon.driver.DriverCorral$useraddLock$,com.databricks.sql.catalyst.plans.logical.ExplainOrCommandResult
26/01/05 09:05:07 INFO PreloadClasses$: Completed preloaded classes from /databricks/driver/preload_class.lst.repl in 9711 ms
26/01/05 09:05:07 INFO ReplDaemon$: Setting up container security, isIptablesEnabled: true, shouldRunAsLowPrivilegeUser: true, isUnityCatalogEnabled: true
26/01/05 09:05:07 INFO ReplDaemon$: Attempting to run: 'enable iptables restrictions for Python'
26/01/05 09:05:12 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:05:11 +0000] "GET /metrics HTTP/1.1" 200 60509 
26/01/05 09:05:13 INFO ReplDaemon$: Attempting to run: 'set up filesystem permissions for Python'
26/01/05 09:05:31 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:05:31 +0000] "GET /metrics HTTP/1.1" 200 60594 
26/01/05 09:05:33 INFO LocalSparkConnectService: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:0 chmod:0
26/01/05 09:05:34 INFO ReplDaemon$: Finished setting up filesystem permissions for low privileged user cluster
26/01/05 09:05:34 INFO ReplDaemon$: Finished setting up container security, took 26902 ms
26/01/05 09:05:34 INFO ReplDaemon$: Attempting to run: 'set up secure ttyd daemon'
26/01/05 09:05:34 INFO ReplDaemon$: Attempting to run: 'set up git_agent daemon'
26/01/05 09:05:34 INFO SessionUserManager$: No user ID counter detected. Proceeding to set one up.
26/01/05 09:05:34 INFO SessionUserManager$: Finished setting up the user ID tracker.
26/01/05 09:05:34 INFO PythonRootEnvSetup$: Resetting the default python executable
26/01/05 09:05:34 INFO VirtualenvCloneHelper: Creating Python cluster virtualenv
26/01/05 09:05:35 INFO VirtualenvCloneHelper: Completed configuration of file permissions and ACL entries for environment root directories
26/01/05 09:05:35 INFO Utils: resolved command to be run: List(virtualenv, /local_disk0/.ephemeral_nfs/cluster_libraries/python, -p, /databricks/python/bin/python, --no-download, --no-setuptools, --no-wheel)
26/01/05 09:05:35 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/cluster_libraries/python
26/01/05 09:05:35 INFO Utils: resolved command to be run: List(/databricks/python/bin/python, -c, import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs])))
26/01/05 09:05:35 INFO Utils: resolved command to be run: List(/local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python, -c, from sysconfig import get_path; print(get_path('purelib')))
26/01/05 09:05:35 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages/sites.pth
26/01/05 09:05:36 INFO ClusterWidePythonEnvManager: Time spent creating Python cluster virtualenv is 1399 ms
26/01/05 09:05:36 INFO ClusterWidePythonEnvManager: Registered /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@329b70b (1 current watcher(s)).
26/01/05 09:05:36 INFO PythonRootEnvSetup$: Attempting to run: 'Update root virtualenv'
26/01/05 09:05:36 INFO PythonRootEnvSetup$: Finished updating /etc/environment
26/01/05 09:05:36 INFO ReplPoolManagerImpl: Initializing REPL factories Set(python, generic)
26/01/05 09:05:36 INFO PythonReplFactory: Starting REPL pool population task.
26/01/05 09:05:36 INFO ReadinessAwareDriverCorral: Adding driverCorral to DriverDaemonRoutingServerBackend
26/01/05 09:05:36 INFO ReplDaemon$: Transitioning REPL Daemon state: WARMUP_STARTED ==> WARMUP_RPC
26/01/05 09:05:36 INFO ReplDaemon$: REPL Daemon is processing warmup RPC.
26/01/05 09:05:36 INFO DriverCorral: Sent a notification to Chauffeur to tell that driver is warmup ready.
26/01/05 09:05:36 INFO ReplDaemon$: Transitioning REPL Daemon state: WARMUP_RPC ==> WAITING_FOR_ASSIGNMENT
26/01/05 09:05:36 INFO ReplDaemon$: REPL Daemon is now waiting for assignment.
26/01/05 09:05:36 INFO ReplWarmupUtils$: Waiting for lazy config to be delivered for REPL VM
26/01/05 09:05:36 INFO ReplDaemon$$anon$1: Thread to send message is ready
26/01/05 09:05:36 INFO SessionUserManager$: Successfully created a user with ID 1003 for spark-b008cfcd-c2b1-4779-aae2-a6.
26/01/05 09:05:36 WARN DriverDaemonRoutingServer$: Unexpected exception: java.lang.IllegalStateException: DriverCorral is not yet ready
java.lang.IllegalStateException: DriverCorral is not yet ready
	at com.databricks.backend.daemon.driver.DriverCorralCompatServerBackend.$anonfun$handlers$28(DriverCorralCompatServerBackend.scala:157)
	at com.databricks.rpc.armeria.JettyCompatibilityWrapperBlocking.$anonfun$unaryRpcHandler$1(CompatServerBackend.scala:473)
	at com.databricks.rpc.armeria.UnaryRpcHandler$.$anonfun$blocking$2(UnaryRpcHandler.scala:442)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$callFunc$2(UnaryRpcHandler.scala:314)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:84)
	at com.databricks.rpc.armeria.UnaryRpcHandler.callFunc(UnaryRpcHandler.scala:314)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.callFuncWithHooks(UnaryRpcHandler.scala:647)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.$anonfun$callFunc$3(UnaryRpcHandler.scala:625)
	at com.databricks.rpc.OperationSpan.$anonfun$wrapFuture$1(OperationSpan.scala:69)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.OperationSpan.withAttributionContext(OperationSpan.scala:22)
	at com.databricks.rpc.OperationSpan.wrapFuture(OperationSpan.scala:68)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.callFunc(UnaryRpcHandler.scala:623)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc0$3(UnaryRpcHandler.scala:274)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.armeria.UnaryRpcHandler.withAttributionContext(UnaryRpcHandler.scala:43)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc0$2(UnaryRpcHandler.scala:234)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleRpc0(UnaryRpcHandler.scala:234)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc$1(UnaryRpcHandler.scala:205)
	at com.databricks.rpc.armeria.server.internal.RequestCompletionTracker.wrap(RequestCompletionTracker.scala:184)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleRpc(UnaryRpcHandler.scala:205)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleJettyRpc(UnaryRpcHandler.scala:88)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.handleJettyRpcWithAggregatedContent(UnaryRpcService.scala:522)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleContextAwareJettyRpcWithAggregatedContent$2(UnaryRpcService.scala:433)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.withAttributionContext(UnaryRpcService.scala:187)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleContextAwareJettyRpcWithAggregatedContent$1(UnaryRpcService.scala:428)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.handleContextAwareJettyRpcWithAggregatedContent(UnaryRpcService.scala:427)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleJettyJsonRpc$2(UnaryRpcService.scala:407)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:84)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:108)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleJettyJsonRpc$1(UnaryRpcService.scala:402)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at com.databricks.threading.DatabricksExecutionContext$InstrumentedRunnable.run(DatabricksExecutionContext.scala:36)
	at grpc_shaded.com.linecorp.armeria.common.DefaultContextAwareRunnable.run(DefaultContextAwareRunnable.java:45)
	at com.databricks.threading.ContextBoundRunnable.$anonfun$run$2(ContextBoundRunnable.scala:16)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.threading.ContextBoundRunnable.withAttributionContext(ContextBoundRunnable.scala:7)
	at com.databricks.threading.ContextBoundRunnable.$anonfun$run$1(ContextBoundRunnable.scala:16)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.threading.ContextBoundRunnable.run(ContextBoundRunnable.scala:15)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$makeContextAware$2(InstrumentedExecutorService.scala:257)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$instrumentationWrapper$1(InstrumentedExecutorService.scala:299)
	at com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)
	at com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)
	at com.databricks.threading.InstrumentedExecutorService.trackActiveThreads(InstrumentedExecutorService.scala:72)
	at com.databricks.threading.InstrumentedExecutorService.instrumentationWrapper(InstrumentedExecutorService.scala:287)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$makeContextAware$1(InstrumentedExecutorService.scala:259)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
26/01/05 09:05:36 ERROR LoggingService: [sreqId=abbc5017, chanId=7a2279ca, raddr=127.0.0.1:53498, laddr=127.0.0.1:6061][h1c://ip-10-152-169-53/#POST] Request: {startTime=2026-01-05T09:05:36.779Z(1767603936779000), length=96B, duration=2633Âµs(2633787ns), scheme=ws+h1c, name=POST, headers=[:method=POST, :path=/?type="com.databricks.api.proto.chauffeur.StartReplRequest", content-length=96, content-type=application/octet-stream]}
26/01/05 09:05:36 ERROR LoggingService: [sreqId=abbc5017, chanId=7a2279ca, raddr=127.0.0.1:53498, laddr=127.0.0.1:6061][h1c://ip-10-152-169-53/#POST] Response: {startTime=2026-01-05T09:05:36.864Z(1767603936864000), length=8292B, duration=0ns, totalDuration=84371Âµs(84371233ns), cause=java.lang.IllegalStateException: DriverCorral is not yet ready, headers=[:status=500, content-length=8292, content-type=application/octet-stream]}
java.lang.IllegalStateException: DriverCorral is not yet ready
	at com.databricks.backend.daemon.driver.DriverCorralCompatServerBackend.$anonfun$handlers$28(DriverCorralCompatServerBackend.scala:157)
	at com.databricks.rpc.armeria.JettyCompatibilityWrapperBlocking.$anonfun$unaryRpcHandler$1(CompatServerBackend.scala:473)
	at com.databricks.rpc.armeria.UnaryRpcHandler$.$anonfun$blocking$2(UnaryRpcHandler.scala:442)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$callFunc$2(UnaryRpcHandler.scala:314)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:84)
	at com.databricks.rpc.armeria.UnaryRpcHandler.callFunc(UnaryRpcHandler.scala:314)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.callFuncWithHooks(UnaryRpcHandler.scala:647)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.$anonfun$callFunc$3(UnaryRpcHandler.scala:625)
	at com.databricks.rpc.OperationSpan.$anonfun$wrapFuture$1(OperationSpan.scala:69)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.OperationSpan.withAttributionContext(OperationSpan.scala:22)
	at com.databricks.rpc.OperationSpan.wrapFuture(OperationSpan.scala:68)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.callFunc(UnaryRpcHandler.scala:623)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc0$3(UnaryRpcHandler.scala:274)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.armeria.UnaryRpcHandler.withAttributionContext(UnaryRpcHandler.scala:43)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc0$2(UnaryRpcHandler.scala:234)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleRpc0(UnaryRpcHandler.scala:234)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc$1(UnaryRpcHandler.scala:205)
	at com.databricks.rpc.armeria.server.internal.RequestCompletionTracker.wrap(RequestCompletionTracker.scala:184)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleRpc(UnaryRpcHandler.scala:205)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleJettyRpc(UnaryRpcHandler.scala:88)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.handleJettyRpcWithAggregatedContent(UnaryRpcService.scala:522)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleContextAwareJettyRpcWithAggregatedContent$2(UnaryRpcService.scala:433)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.withAttributionContext(UnaryRpcService.scala:187)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleContextAwareJettyRpcWithAggregatedContent$1(UnaryRpcService.scala:428)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.handleContextAwareJettyRpcWithAggregatedContent(UnaryRpcService.scala:427)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleJettyJsonRpc$2(UnaryRpcService.scala:407)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:84)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:108)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleJettyJsonRpc$1(UnaryRpcService.scala:402)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at com.databricks.threading.DatabricksExecutionContext$InstrumentedRunnable.run(DatabricksExecutionContext.scala:36)
	at grpc_shaded.com.linecorp.armeria.common.DefaultContextAwareRunnable.run(DefaultContextAwareRunnable.java:45)
	at com.databricks.threading.ContextBoundRunnable.$anonfun$run$2(ContextBoundRunnable.scala:16)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.threading.ContextBoundRunnable.withAttributionContext(ContextBoundRunnable.scala:7)
	at com.databricks.threading.ContextBoundRunnable.$anonfun$run$1(ContextBoundRunnable.scala:16)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.threading.ContextBoundRunnable.run(ContextBoundRunnable.scala:15)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$makeContextAware$2(InstrumentedExecutorService.scala:257)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$instrumentationWrapper$1(InstrumentedExecutorService.scala:299)
	at com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)
	at com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)
	at com.databricks.threading.InstrumentedExecutorService.trackActiveThreads(InstrumentedExecutorService.scala:72)
	at com.databricks.threading.InstrumentedExecutorService.instrumentationWrapper(InstrumentedExecutorService.scala:287)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$makeContextAware$1(InstrumentedExecutorService.scala:259)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
26/01/05 09:05:36 INFO DriverCorral: Loading the root classloader
26/01/05 09:05:36 INFO ReplOuterWrapper: DriverWrapper created for REPL ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false)
26/01/05 09:05:36 INFO PythonDriverWrapper: REPL status transitioned to Starting ReplId-24b25-f002b-3e467-0 (3)
26/01/05 09:05:36 INFO PythonDriverWrapper: Starting ReplId-24b25-f002b-3e467-0 - driverStatus transitioned to Starting (4)
26/01/05 09:05:37 INFO JupyterDriverLocal: Setting up Python REPL ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false), initializing JupyterDriverLocal (5 - 0)
26/01/05 09:05:37 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false)
26/01/05 09:05:37 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-24b25-f002b-3e467-0
26/01/05 09:05:37 INFO DriverCorral: Received warmup StartRepl request
26/01/05 09:05:38 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
26/01/05 09:05:38 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false): started Py4J Gateway Server (5 - 1)
26/01/05 09:05:38 INFO VirtualenvCloneHelper: Creating Python notebook virtualenv for b008cfcd-c2b1-4779-aae2-a66cd14bed36 with user spark-b008cfcd-c2b1-4779-aae2-a6
26/01/05 09:05:38 INFO Utils: resolved command to be run: List(/bin/su, spark-b008cfcd-c2b1-4779-aae2-a6, -c, virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-b008cfcd-c2b1-4779-aae2-a66cd14bed36 -p /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python --no-download --no-setuptools --no-wheel)
26/01/05 09:05:38 INFO ReplManagerImpl: REPL ReplId-19b8d-679cf-6 finished addReplToExecutionContext (1)
26/01/05 09:05:38 INFO PythonReplFactory: Cold-start repl creation for: python, ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true)
26/01/05 09:05:38 INFO SessionUserManager$: Successfully created a user with ID 1004 for spark-4901781e-b746-47be-b1f3-9f.
26/01/05 09:05:39 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:05:39 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-b008cfcd-c2b1-4779-aae2-a66cd14bed36
26/01/05 09:05:39 INFO Utils: resolved command to be run: List(/bin/su, spark-b008cfcd-c2b1-4779-aae2-a6, -c, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python -c "import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs]))")
26/01/05 09:05:39 INFO Utils: resolved command to be run: List(/bin/su, spark-b008cfcd-c2b1-4779-aae2-a6, -c, /local_disk0/.ephemeral_nfs/envs/pythonEnv-b008cfcd-c2b1-4779-aae2-a66cd14bed36/bin/python -c "from sysconfig import get_path; print(get_path('purelib'))")
26/01/05 09:05:39 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-b008cfcd-c2b1-4779-aae2-a66cd14bed36/lib/python3.12/site-packages/sites.pth
26/01/05 09:05:39 INFO ReplOuterWrapper: DriverWrapper created for REPL ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true)
26/01/05 09:05:39 INFO ReplManagerImpl: Adding repl ReplId-19b8d-679cf-6 to execution context 7120639335594363157 with Spark Connect session ID: Some(84c57d2f-f694-4d11-a2fb-1d6b58ed623b) (2)
26/01/05 09:05:39 INFO PythonDriverWrapper: REPL status transitioned to Starting ReplId-19b8d-679cf-6 (3)
26/01/05 09:05:39 INFO ReplManagerImpl: StartReplOptions: 
26/01/05 09:05:39 INFO PythonDriverWrapper: Starting ReplId-19b8d-679cf-6 - driverStatus transitioned to Starting (4)
26/01/05 09:05:39 INFO JupyterDriverLocal: Setting up Python REPL ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true), initializing JupyterDriverLocal (5 - 0)
26/01/05 09:05:39 INFO NotebookScopedPythonEnvManager: Time spent creating Python notebook virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-b008cfcd-c2b1-4779-aae2-a66cd14bed36 is 1027 ms
26/01/05 09:05:39 INFO NotebookScopedPythonEnvManager: Check environment isGPU: false
26/01/05 09:05:39 INFO JupyterDriverLocal: Created Python Environment Manager for REPL ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 2)
26/01/05 09:05:39 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-b008cfcd-c2b1-4779-aae2-a66cd14bed36/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@71d0bc01 (2 current watcher(s)).
26/01/05 09:05:39 INFO JupyterDriverLocal: Created LSP backend symlink for REPL ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 3)
26/01/05 09:05:39 INFO JupyterDriverLocal: Sandbox API is not used in REPL
26/01/05 09:05:39 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-b008cfcd-c2b1-4779-aae2-a66cd14bed36/python_start_notebook_scoped.sh, /databricks/spark/python/pyspark/wrapped_python.py, spark-b008cfcd-c2b1-4779-aae2-a6, /local_disk0/.ephemeral_nfs/envs/pythonEnv-b008cfcd-c2b1-4779-aae2-a66cd14bed36/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/33495dae3dcddb8d1fb880ce14f546f480c5070dd24d7a6b99176e4ce362f87f.json]
26/01/05 09:05:39 INFO IpykernelUtils$: Established and started ipyKernelProcess for REPL ReplId-24b25-f002b-3e467-0 (5 - 4)
26/01/05 09:05:39 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process with ReplId=ReplId-24b25-f002b-3e467-0 in repl cgroup
26/01/05 09:05:39 INFO IpykernelUtils$: Configured ipykernel stdout and stdin (5 - 5)
26/01/05 09:05:39 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true)
26/01/05 09:05:39 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-19b8d-679cf-6
26/01/05 09:05:39 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
26/01/05 09:05:39 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true): started Py4J Gateway Server (5 - 1)
26/01/05 09:05:39 INFO VirtualenvCloneHelper: Creating Python notebook virtualenv for 4901781e-b746-47be-b1f3-9f7581da43ac with user spark-4901781e-b746-47be-b1f3-9f
26/01/05 09:05:39 INFO Utils: resolved command to be run: List(/bin/su, spark-4901781e-b746-47be-b1f3-9f, -c, virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-4901781e-b746-47be-b1f3-9f7581da43ac -p /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python --no-download --no-setuptools --no-wheel)
26/01/05 09:05:40 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-4901781e-b746-47be-b1f3-9f7581da43ac
26/01/05 09:05:40 INFO Utils: resolved command to be run: List(/bin/su, spark-4901781e-b746-47be-b1f3-9f, -c, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python -c "import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs]))")
26/01/05 09:05:40 INFO Utils: resolved command to be run: List(/bin/su, spark-4901781e-b746-47be-b1f3-9f, -c, /local_disk0/.ephemeral_nfs/envs/pythonEnv-4901781e-b746-47be-b1f3-9f7581da43ac/bin/python -c "from sysconfig import get_path; print(get_path('purelib'))")
26/01/05 09:05:40 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-4901781e-b746-47be-b1f3-9f7581da43ac/lib/python3.12/site-packages/sites.pth
26/01/05 09:05:40 INFO NotebookScopedPythonEnvManager: Time spent creating Python notebook virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-4901781e-b746-47be-b1f3-9f7581da43ac is 700 ms
26/01/05 09:05:40 INFO NotebookScopedPythonEnvManager: Check environment isGPU: false
26/01/05 09:05:40 INFO JupyterDriverLocal: Created Python Environment Manager for REPL ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true) (5 - 2)
26/01/05 09:05:40 INFO JupyterDriverLocal: Created LSP backend symlink for REPL ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true) (5 - 3)
26/01/05 09:05:40 INFO JupyterDriverLocal: Sandbox API is not used in REPL
26/01/05 09:05:40 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-4901781e-b746-47be-b1f3-9f7581da43ac/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@6c30da58 (3 current watcher(s)).
26/01/05 09:05:40 INFO IpykernelUtils$: Connection file updated for REPL ReplId-24b25-f002b-3e467-0 (5 - 6)
26/01/05 09:05:40 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-4901781e-b746-47be-b1f3-9f7581da43ac/python_start_notebook_scoped.sh, /databricks/spark/python/pyspark/wrapped_python.py, spark-4901781e-b746-47be-b1f3-9f, /local_disk0/.ephemeral_nfs/envs/pythonEnv-4901781e-b746-47be-b1f3-9f7581da43ac/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/a2b1473c37f77fdaea2ace1e0b3de8480d6a2455f08e8f455b15ddc7137db771.json]
26/01/05 09:05:40 INFO JupyterDriverLocal: iPykernel process started and configured for REPL ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 7)
26/01/05 09:05:40 INFO IpykernelUtils$: Established and started ipyKernelProcess for REPL ReplId-19b8d-679cf-6 (5 - 4)
26/01/05 09:05:40 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process with ReplId=ReplId-19b8d-679cf-6 in repl cgroup
26/01/05 09:05:40 INFO IpykernelUtils$: Configured ipykernel stdout and stdin (5 - 5)
26/01/05 09:05:40 INFO JupyterDriverLocal: Jupyter client and comm channels configured for repl ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 8)
26/01/05 09:05:40 INFO JupyterDriverLocal: Watchdog thread started for repl ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 9)
26/01/05 09:05:41 INFO IpykernelUtils$: Connection file updated for REPL ReplId-19b8d-679cf-6 (5 - 6)
26/01/05 09:05:41 INFO JupyterDriverLocal: iPykernel process started and configured for REPL ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true) (5 - 7)
26/01/05 09:05:41 INFO JupyterDriverLocal: Jupyter client and comm channels configured for repl ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true) (5 - 8)
26/01/05 09:05:41 INFO JupyterDriverLocal: Watchdog thread started for repl ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true) (5 - 9)
26/01/05 09:05:42 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:05:43 INFO JupyterDriverLocal: JupyterKernelListener instantiated and started for REPL ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true) (5 - 10)
26/01/05 09:05:43 INFO PythonDriverWrapper: Driver instantiated for ReplId-19b8d-679cf-6 (6)
26/01/05 09:05:43 INFO NotebookScopedPythonEnvManager: Pip metadata is empty, cleanup old pip configuration if exists
26/01/05 09:05:43 INFO PythonDriverWrapper: REPL started but is idle: ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true) (7)
26/01/05 09:05:43 INFO PythonDriverWrapper: setupRepl:ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true): finished to load
26/01/05 09:05:43 INFO PythonDriverWrapper: Finished setting-up REPL ReplId-19b8d-679cf-6, accepting commands (8)
26/01/05 09:05:43 INFO JupyterDriverLocal: JupyterKernelListener instantiated and started for REPL ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 10)
26/01/05 09:05:43 INFO PythonDriverWrapper: Driver instantiated for ReplId-24b25-f002b-3e467-0 (6)
26/01/05 09:05:43 INFO PythonDriverWrapper: REPL started but is idle: ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (7)
26/01/05 09:05:43 INFO PythonDriverWrapper: Skipping message because pooled repl is not allocated yet AnswerReplStarted(ReplId-7)
26/01/05 09:05:43 INFO PythonDriverWrapper: setupRepl:ReplInfo(driverReplId=ReplId-24b25-f002b-3e467-0, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false): finished to load
26/01/05 09:05:43 INFO PythonDriverWrapper: Finished setting-up REPL ReplId-24b25-f002b-3e467-0, accepting commands (8)
26/01/05 09:05:43 INFO ProgressReporter$: Added result fetcher for 7_0_7
26/01/05 09:05:43 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2531): time:[4026531834]
26/01/05 09:05:43 WARN WsfsHttpClient: Host http://databricks.node.host.local does not exist: java.net.UnknownHostException: databricks.node.host.local: Name or service not known
26/01/05 09:05:43 INFO ProgressReporter$: Added result fetcher for 1767603936502_9059087499866333734_warmup-0
26/01/05 09:05:43 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2593): time:[4026531834]
26/01/05 09:05:43 WARN WsfsHttpClient: Host http://databricks.node.host.local does not exist: java.net.UnknownHostException: databricks.node.host.local
26/01/05 09:05:43 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2531): time:[4026531834]
26/01/05 09:05:43 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2593): time:[4026531834]
26/01/05 09:05:43 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(Mon Jan  5 09:05:41 2026 Connection to spark from PID  2593
Mon Jan  5 09:05:41 2026 Initialized gateway on port 44091
Mon Jan  5 09:05:41 2026 Connected to spark.
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:05:43 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(Mon Jan  5 09:05:40 2026 Connection to spark from PID  2531
Mon Jan  5 09:05:40 2026 Initialized gateway on port 44743
Mon Jan  5 09:05:40 2026 Connected to spark.
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:05:43 INFO ProgressReporter$: Reporting progress for running commands: 1767603936502_9059087499866333734_warmup-0
26/01/05 09:05:44 INFO ProgressReporter$: Removed result fetcher for 1767603936502_9059087499866333734_warmup-0
26/01/05 09:05:44 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1767603936502_9059087499866333734_warmup-0
26/01/05 09:05:45 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:05:45 INFO ProgressReporter$: Added result fetcher for 1767603936502_7007780744055487725_warmup-1
26/01/05 09:05:45 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2593): time:[4026531834]
26/01/05 09:05:45 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2593): time:[4026531834]
26/01/05 09:05:45 INFO ProgressReporter$: Removed result fetcher for 1767603936502_7007780744055487725_warmup-1
26/01/05 09:05:45 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1767603936502_7007780744055487725_warmup-1
26/01/05 09:05:45 INFO ProgressReporter$: Added result fetcher for 1767603936502_7629675272964212965_warmup-2
26/01/05 09:05:45 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2593): time:[4026531834]
26/01/05 09:05:45 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2593): time:[4026531834]
26/01/05 09:05:45 INFO ProgressReporter$: Removed result fetcher for 1767603936502_7629675272964212965_warmup-2
26/01/05 09:05:45 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1767603936502_7629675272964212965_warmup-2
26/01/05 09:05:46 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:05:46 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:05:46 INFO ReplCrashUtils$: python shell exit code: 143; replId: ReplId-19b8d-679cf-6, pid: 2593
26/01/05 09:05:46 INFO PythonDriverWrapper: Stopping main loop for REPL ReplId-19b8d-679cf-6
26/01/05 09:05:46 INFO ReplManagerImpl: ReplInfo(driverReplId=ReplId-19b8d-679cf-6, chauffeurReplId=ReplId-19b8d-679cf-6,
 executionContextId=Some(ExecutionContextIdV2(7120639335594363157)), lazyInfoInitialized=true) successfully discarded
26/01/05 09:05:46 WARN SessionUserManager$: Fail to kill all processes by user spark-4901781e-b746-47be-b1f3-9f, ret code: 1, errMsg: Cannot find user spark-4901781e-b746-47be-b1f3-9f

26/01/05 09:05:48 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:05:50 INFO AdviceStore: Added advice MLFLOW_TRACKING_PYTHON_ADVICE (version 1) for executionId -, jobGroupId 7_0_7: Instrument ML code with MLflow Use MLflow to track metrics, params, and models from your training code. Learn more (applications/mlflow/quick-start-python.html)
26/01/05 09:05:50 INFO ProgressReporter$: Removed result fetcher for 7_0_7
26/01/05 09:05:50 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 7_0_7
26/01/05 09:05:50 INFO PythonDriverWrapper: Skipping message because pooled repl is not allocated yet AnswerExecuteCommand(ReplId-7,ExecutionId(7),RunnableCommandId(0),ListResults(List(AnsiResult(1
,Some(stdout),Map(),Map(),List(),List(),Map())),Map(),Map(),List(),List(),Map()),Some(Progress(ExecutionContextId(7),RunnableCommandId(0),ExecutionId(7),ArraySeq(),List(),Some(CommandStatus(0,RUNNING_COMMAND,1767603943198,Running command...,Map())),List(Advice(MLFLOW_TRACKING_PYTHON_ADVICE,1,List(Map(componentType -> header, content -> Instrument ML code with MLflow, params -> Map()), Map(componentType -> text, content -> Use MLflow to track metrics, params, and models from your training code., params -> Map()), Map(componentType -> docsLink, docsPath -> applications/mlflow/quick-start-python.html, text -> Learn more)),7_0_7)),List(),Some(1516327779))),1767603943198,1767603950228)
26/01/05 09:05:50 INFO JediPrewarmHelper$: Finish executing pre-warm jedi command
26/01/05 09:05:50 INFO ReplDaemon$: Transitioning REPL Daemon state: WAITING_FOR_ASSIGNMENT ==> WARMUP_FINISHED_SUCCESS
26/01/05 09:05:50 INFO ReplDaemon$: REPL Daemon REPL warmup finished successfully.
26/01/05 09:05:50 INFO SessionUserManager$: Successfully created a user with ID 1005 for spark-4e594d21-75c8-489f-8db0-41.
26/01/05 09:05:50 INFO ReplOuterWrapper: DriverWrapper created for REPL ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false)
26/01/05 09:05:50 INFO PythonDriverWrapper: REPL status transitioned to Starting ReplId-3e8d5-1a720-5a50a-4 (3)
26/01/05 09:05:50 INFO PythonDriverWrapper: Starting ReplId-3e8d5-1a720-5a50a-4 - driverStatus transitioned to Starting (4)
26/01/05 09:05:50 INFO JupyterDriverLocal: Setting up Python REPL ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false), initializing JupyterDriverLocal (5 - 0)
26/01/05 09:05:51 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false)
26/01/05 09:05:51 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-3e8d5-1a720-5a50a-4
26/01/05 09:05:51 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
26/01/05 09:05:51 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false): started Py4J Gateway Server (5 - 1)
26/01/05 09:05:51 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:05:51 INFO VirtualenvCloneHelper: Creating Python notebook virtualenv for 4e594d21-75c8-489f-8db0-41c5fa21197c with user spark-4e594d21-75c8-489f-8db0-41
26/01/05 09:05:51 INFO Utils: resolved command to be run: List(/bin/su, spark-4e594d21-75c8-489f-8db0-41, -c, virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-4e594d21-75c8-489f-8db0-41c5fa21197c -p /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python --no-download --no-setuptools --no-wheel)
26/01/05 09:05:51 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-4e594d21-75c8-489f-8db0-41c5fa21197c
26/01/05 09:05:51 INFO Utils: resolved command to be run: List(/bin/su, spark-4e594d21-75c8-489f-8db0-41, -c, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python -c "import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs]))")
26/01/05 09:05:51 INFO Utils: resolved command to be run: List(/bin/su, spark-4e594d21-75c8-489f-8db0-41, -c, /local_disk0/.ephemeral_nfs/envs/pythonEnv-4e594d21-75c8-489f-8db0-41c5fa21197c/bin/python -c "from sysconfig import get_path; print(get_path('purelib'))")
26/01/05 09:05:51 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-4e594d21-75c8-489f-8db0-41c5fa21197c/lib/python3.12/site-packages/sites.pth
26/01/05 09:05:51 INFO NotebookScopedPythonEnvManager: Time spent creating Python notebook virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-4e594d21-75c8-489f-8db0-41c5fa21197c is 544 ms
26/01/05 09:05:51 INFO NotebookScopedPythonEnvManager: Check environment isGPU: false
26/01/05 09:05:51 INFO JupyterDriverLocal: Created Python Environment Manager for REPL ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 2)
26/01/05 09:05:51 INFO JupyterDriverLocal: Created LSP backend symlink for REPL ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 3)
26/01/05 09:05:51 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-4e594d21-75c8-489f-8db0-41c5fa21197c/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@7c640065 (3 current watcher(s)).
26/01/05 09:05:51 INFO JupyterDriverLocal: Sandbox API is not used in REPL
26/01/05 09:05:51 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-4e594d21-75c8-489f-8db0-41c5fa21197c/python_start_notebook_scoped.sh, /databricks/spark/python/pyspark/wrapped_python.py, spark-4e594d21-75c8-489f-8db0-41, /local_disk0/.ephemeral_nfs/envs/pythonEnv-4e594d21-75c8-489f-8db0-41c5fa21197c/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/e79f05a40564dd90ba851157df9e0178702288f1170965609566890e845dcff6.json]
26/01/05 09:05:51 INFO IpykernelUtils$: Established and started ipyKernelProcess for REPL ReplId-3e8d5-1a720-5a50a-4 (5 - 4)
26/01/05 09:05:51 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process with ReplId=ReplId-3e8d5-1a720-5a50a-4 in repl cgroup
26/01/05 09:05:51 INFO IpykernelUtils$: Configured ipykernel stdout and stdin (5 - 5)
26/01/05 09:05:52 INFO IpykernelUtils$: Connection file updated for REPL ReplId-3e8d5-1a720-5a50a-4 (5 - 6)
26/01/05 09:05:52 INFO JupyterDriverLocal: iPykernel process started and configured for REPL ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 7)
26/01/05 09:05:52 INFO JupyterDriverLocal: Jupyter client and comm channels configured for repl ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 8)
26/01/05 09:05:52 INFO JupyterDriverLocal: Watchdog thread started for repl ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 9)
26/01/05 09:05:53 INFO JupyterDriverLocal: JupyterKernelListener instantiated and started for REPL ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 10)
26/01/05 09:05:53 INFO PythonDriverWrapper: Driver instantiated for ReplId-3e8d5-1a720-5a50a-4 (6)
26/01/05 09:05:53 INFO PythonDriverWrapper: REPL started but is idle: ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (7)
26/01/05 09:05:53 INFO PythonDriverWrapper: Skipping message because pooled repl is not allocated yet AnswerReplStarted(ReplId-7)
26/01/05 09:05:53 INFO PythonDriverWrapper: setupRepl:ReplInfo(driverReplId=ReplId-3e8d5-1a720-5a50a-4, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false): finished to load
26/01/05 09:05:53 INFO PythonDriverWrapper: Finished setting-up REPL ReplId-3e8d5-1a720-5a50a-4, accepting commands (8)
26/01/05 09:05:53 INFO ProgressReporter$: Added result fetcher for 7_0_7
26/01/05 09:05:53 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2789): time:[4026531834]
26/01/05 09:05:53 WARN WsfsHttpClient: Host http://databricks.node.host.local does not exist: java.net.UnknownHostException: databricks.node.host.local
26/01/05 09:05:53 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2789): time:[4026531834]
26/01/05 09:05:53 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(Mon Jan  5 09:05:52 2026 Connection to spark from PID  2789
Mon Jan  5 09:05:52 2026 Initialized gateway on port 41065
Mon Jan  5 09:05:52 2026 Connected to spark.
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:05:54 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:05:57 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:05:58 INFO ProgressReporter$: Removed result fetcher for 7_0_7
26/01/05 09:05:58 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 7_0_7
26/01/05 09:05:58 INFO PythonDriverWrapper: Skipping message because pooled repl is not allocated yet AnswerExecuteCommand(ReplId-7,ExecutionId(7),RunnableCommandId(0),ListResults(List(AnsiResult(1
,Some(stdout),Map(),Map(),List(),List(),Map())),Map(),Map(),List(),List(),Map()),Some(Progress(ExecutionContextId(7),RunnableCommandId(0),ExecutionId(7),ArraySeq(),List(),Some(CommandStatus(0,RUNNING_COMMAND,1767603953288,Running command...,Map())),List(Advice(MLFLOW_TRACKING_PYTHON_ADVICE,1,List(Map(componentType -> header, content -> Instrument ML code with MLflow, params -> Map()), Map(componentType -> text, content -> Use MLflow to track metrics, params, and models from your training code., params -> Map()), Map(componentType -> docsLink, docsPath -> applications/mlflow/quick-start-python.html, text -> Learn more)),7_0_7)),List(),Some(-485830401))),1767603953288,1767603958721)
26/01/05 09:05:58 INFO JediPrewarmHelper$: Finish executing pre-warm jedi command
26/01/05 09:05:58 INFO SessionUserManager$: Successfully created a user with ID 1006 for spark-d0a7b869-5d38-48ae-b14d-91.
26/01/05 09:05:59 INFO ReplOuterWrapper: DriverWrapper created for REPL ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false)
26/01/05 09:05:59 INFO PythonDriverWrapper: REPL status transitioned to Starting ReplId-27919-53680-8440f (3)
26/01/05 09:05:59 INFO PythonDriverWrapper: Starting ReplId-27919-53680-8440f - driverStatus transitioned to Starting (4)
26/01/05 09:05:59 INFO JupyterDriverLocal: Setting up Python REPL ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false), initializing JupyterDriverLocal (5 - 0)
26/01/05 09:05:59 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false)
26/01/05 09:05:59 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-27919-53680-8440f
26/01/05 09:05:59 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
26/01/05 09:05:59 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false): started Py4J Gateway Server (5 - 1)
26/01/05 09:05:59 INFO VirtualenvCloneHelper: Creating Python notebook virtualenv for d0a7b869-5d38-48ae-b14d-91a855ec1603 with user spark-d0a7b869-5d38-48ae-b14d-91
26/01/05 09:05:59 INFO Utils: resolved command to be run: List(/bin/su, spark-d0a7b869-5d38-48ae-b14d-91, -c, virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0a7b869-5d38-48ae-b14d-91a855ec1603 -p /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python --no-download --no-setuptools --no-wheel)
26/01/05 09:06:00 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0a7b869-5d38-48ae-b14d-91a855ec1603
26/01/05 09:06:00 INFO Utils: resolved command to be run: List(/bin/su, spark-d0a7b869-5d38-48ae-b14d-91, -c, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python -c "import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs]))")
26/01/05 09:06:00 INFO Utils: resolved command to be run: List(/bin/su, spark-d0a7b869-5d38-48ae-b14d-91, -c, /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0a7b869-5d38-48ae-b14d-91a855ec1603/bin/python -c "from sysconfig import get_path; print(get_path('purelib'))")
26/01/05 09:06:00 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:00 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0a7b869-5d38-48ae-b14d-91a855ec1603/lib/python3.12/site-packages/sites.pth
26/01/05 09:06:00 INFO NotebookScopedPythonEnvManager: Time spent creating Python notebook virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0a7b869-5d38-48ae-b14d-91a855ec1603 is 705 ms
26/01/05 09:06:00 INFO NotebookScopedPythonEnvManager: Check environment isGPU: false
26/01/05 09:06:00 INFO JupyterDriverLocal: Created Python Environment Manager for REPL ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 2)
26/01/05 09:06:00 INFO JupyterDriverLocal: Created LSP backend symlink for REPL ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 3)
26/01/05 09:06:00 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0a7b869-5d38-48ae-b14d-91a855ec1603/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@24d16c5c (4 current watcher(s)).
26/01/05 09:06:00 INFO JupyterDriverLocal: Sandbox API is not used in REPL
26/01/05 09:06:00 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0a7b869-5d38-48ae-b14d-91a855ec1603/python_start_notebook_scoped.sh, /databricks/spark/python/pyspark/wrapped_python.py, spark-d0a7b869-5d38-48ae-b14d-91, /local_disk0/.ephemeral_nfs/envs/pythonEnv-d0a7b869-5d38-48ae-b14d-91a855ec1603/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/c3cd16f05ab2a7d9b59067514eef8d7bf43cce5a3fc15f0f2bbde27c420ceb64.json]
26/01/05 09:06:00 INFO IpykernelUtils$: Established and started ipyKernelProcess for REPL ReplId-27919-53680-8440f (5 - 4)
26/01/05 09:06:00 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process with ReplId=ReplId-27919-53680-8440f in repl cgroup
26/01/05 09:06:00 INFO IpykernelUtils$: Configured ipykernel stdout and stdin (5 - 5)
26/01/05 09:06:00 INFO IpykernelUtils$: Connection file updated for REPL ReplId-27919-53680-8440f (5 - 6)
26/01/05 09:06:00 INFO JupyterDriverLocal: iPykernel process started and configured for REPL ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 7)
26/01/05 09:06:00 INFO JupyterDriverLocal: Jupyter client and comm channels configured for repl ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 8)
26/01/05 09:06:00 INFO JupyterDriverLocal: Watchdog thread started for repl ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 9)
26/01/05 09:06:01 INFO JupyterDriverLocal: JupyterKernelListener instantiated and started for REPL ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (5 - 10)
26/01/05 09:06:01 INFO PythonDriverWrapper: Driver instantiated for ReplId-27919-53680-8440f (6)
26/01/05 09:06:01 INFO PythonDriverWrapper: REPL started but is idle: ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false) (7)
26/01/05 09:06:01 INFO PythonDriverWrapper: Skipping message because pooled repl is not allocated yet AnswerReplStarted(ReplId-7)
26/01/05 09:06:01 INFO PythonDriverWrapper: setupRepl:ReplInfo(driverReplId=ReplId-27919-53680-8440f, chauffeurReplId=ReplId-7,
 executionContextId=None, lazyInfoInitialized=false): finished to load
26/01/05 09:06:01 INFO PythonDriverWrapper: Finished setting-up REPL ReplId-27919-53680-8440f, accepting commands (8)
26/01/05 09:06:01 INFO ProgressReporter$: Added result fetcher for 7_0_7
26/01/05 09:06:01 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2897): time:[4026531834]
26/01/05 09:06:01 WARN WsfsHttpClient: Host http://databricks.node.host.local does not exist: java.net.UnknownHostException: databricks.node.host.local: Name or service not known
26/01/05 09:06:01 INFO LocalFuseProcess: Time namespace for current process (registered process pid=2897): time:[4026531834]
26/01/05 09:06:01 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(Mon Jan  5 09:06:01 2026 Connection to spark from PID  2897
Mon Jan  5 09:06:01 2026 Initialized gateway on port 44365
Mon Jan  5 09:06:01 2026 Connected to spark.
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:06:03 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:06 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:07 INFO ProgressReporter$: Removed result fetcher for 7_0_7
26/01/05 09:06:07 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 7_0_7
26/01/05 09:06:07 INFO PythonDriverWrapper: Skipping message because pooled repl is not allocated yet AnswerExecuteCommand(ReplId-7,ExecutionId(7),RunnableCommandId(0),ListResults(List(AnsiResult(1
,Some(stdout),Map(),Map(),List(),List(),Map())),Map(),Map(),List(),List(),Map()),Some(Progress(ExecutionContextId(7),RunnableCommandId(0),ExecutionId(7),ArraySeq(),List(),Some(CommandStatus(0,RUNNING_COMMAND,1767603961845,Running command...,Map())),List(Advice(MLFLOW_TRACKING_PYTHON_ADVICE,1,List(Map(componentType -> header, content -> Instrument ML code with MLflow, params -> Map()), Map(componentType -> text, content -> Use MLflow to track metrics, params, and models from your training code., params -> Map()), Map(componentType -> docsLink, docsPath -> applications/mlflow/quick-start-python.html, text -> Learn more)),7_0_7)),List(),Some(1053308573))),1767603961845,1767603967800)
26/01/05 09:06:07 INFO JediPrewarmHelper$: Finish executing pre-warm jedi command
26/01/05 09:06:09 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:12 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:15 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:16 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:06:16 +0000] "GET /metrics HTTP/1.1" 200 78877 
26/01/05 09:06:18 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:21 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:24 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:27 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:30 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:33 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:36 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:39 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:42 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:45 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:48 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:51 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:54 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:06:57 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:00 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:01 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:07:01 +0000] "GET /metrics HTTP/1.1" 200 78914 
26/01/05 09:07:03 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:06 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:09 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:12 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:15 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:18 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:21 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:24 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:27 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:30 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:32 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:07:32 +0000] "GET /metrics HTTP/1.1" 200 78850 
26/01/05 09:07:33 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:36 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:39 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:42 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:45 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:46 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:07:46 +0000] "GET /metrics HTTP/1.1" 200 78980 
26/01/05 09:07:48 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:51 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:54 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:07:57 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:00 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:03 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:06 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:09 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:12 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:15 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:18 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:21 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:24 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:27 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:30 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:31 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:08:31 +0000] "GET /metrics HTTP/1.1" 200 78933 
26/01/05 09:08:33 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:36 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:39 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:42 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:45 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:48 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:51 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:54 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:08:57 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:00 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:03 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:06 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:09 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:12 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:15 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:16 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:09:16 +0000] "GET /metrics HTTP/1.1" 200 79012 
26/01/05 09:09:18 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:21 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:24 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:27 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:30 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:32 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:09:32 +0000] "GET /metrics HTTP/1.1" 200 79008 
26/01/05 09:09:33 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:36 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:39 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:42 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:45 WARN LazyConfUtils$: File /databricks/secrets/config.json not found
26/01/05 09:09:47 WARN SparkContext: Requesting executors is not supported by current scheduler.
26/01/05 09:09:47 INFO DeadlockDetector: Requested deadlock detection caused by: DAG_SCHEDULER_NO_ACTIVE_JOB
26/01/05 09:09:47 INFO HangingThreadDetector: Requested hanging thread detection caused by: DAG_SCHEDULER_NO_ACTIVE_JOB
26/01/05 09:09:47 INFO LazyConfUtils$: File /databricks/secrets/config.json is not empty
26/01/05 09:09:47 INFO LazyConfUtils$: Successfully parsed content from file /databricks/secrets/config.json
26/01/05 09:09:47 INFO ReplWarmupUtils$: Attribution context updated with usage tags from lazy config
26/01/05 09:09:47 INFO ReplWarmupUtils$: Finished waiting for lazy config for REPL VM
26/01/05 09:09:47 INFO ReplSaferUtils$: Start refreshing SAFEr flags for ReplDaemon
26/01/05 09:09:47 INFO ReplSaferUtils$: Successfully finished refreshing SAFEr flags for ReplDaemon
26/01/05 09:09:47 INFO ReplDaemon$: Transitioning REPL Daemon state: WARMUP_FINISHED_SUCCESS ==> LAZY_CONFIG_RECEIVED
26/01/05 09:09:47 INFO ReplDaemon$: REPL Daemon has received lazy config.
26/01/05 09:09:47 INFO DatabricksTraceExporter$: Tracing: Spark logging predicate set. Initial value: true
26/01/05 09:09:47 INFO ReplDaemon: Tracing: SAFEr driverSpanLogsEnabled flag predicate is set.
26/01/05 09:09:47 INFO ReplDaemon: Tracing: Driver tracing is enabled via SAFEr flag.
26/01/05 09:09:47 INFO DatabricksTraceExporter: Trace exporter starting... @ https://jaeger-collector-privileged-worker.privileged.staging.dbns.databricks.com/api/traces
26/01/05 09:09:47 INFO DatabricksTraceExporter: Found value for DPP_TRACING_LOGGING_ENABLED: None
26/01/05 09:09:47 INFO ReplDaemon: Tracing: Successfully enabled trace exporter
26/01/05 09:09:47 INFO DatabricksTraceExporter$: Tracing: Spark trace enabled predicate set. Initial value: true
26/01/05 09:09:47 INFO ReplDaemon: Tracing: SAFEr kill switch predicate is set based on tracingEnabled flag.
26/01/05 09:09:47 INFO DatabricksSparkTracingConfig$: Tracing: Trace generation disabled predicate set. Initial value: false
26/01/05 09:09:47 INFO ReplDaemon: Tracing: SAFEr driverTraceGenerationDisabled flag predicate is set.
26/01/05 09:09:47 INFO DriverCorral: Sent a notification to Chauffeur to tell that driver is ready.
26/01/05 09:09:47 INFO ReplDaemon: Notified chauffeur that driver is ready
26/01/05 09:09:47 INFO ReplDaemon$: Transitioning REPL Daemon state: LAZY_CONFIG_RECEIVED ==> ASSIGNED
26/01/05 09:09:47 INFO ReplDaemon$: REPL Daemon has been assigned and is ready to handle customer requests.
26/01/05 09:09:47 INFO ArmeriaCommChannelServer: Binding to host address: ip-10-152-169-53/10.152.169.53
26/01/05 09:09:47 INFO ArmeriaSslConfigurer$: Using these TLS settings for Armeria server listening on :6062
 mTLS enabled: true
 protocols: 
 ciphers: 

26/01/05 09:09:47 INFO DatabricksServerBuilder: Setting server max connection age to 3600000 ms
26/01/05 09:09:47 INFO DatabricksServerBuilder: Set http2MaxStreamsPerConnection to 100
26/01/05 09:09:47 INFO DatabricksServerBuilder: No standard error handler is set for the server, using DatabricksDefaultServerErrorHandler instead.
26/01/05 09:09:47 WARN config: Weak cipher suite TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA enabled for ShadedSslContextFactory@1c2c2606[provider=null,keyStore=null,trustStore=null]
26/01/05 09:09:47 WARN config: Weak cipher suite TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA enabled for ShadedSslContextFactory@1c2c2606[provider=null,keyStore=null,trustStore=null]
26/01/05 09:09:47 INFO DatabricksServerBuilder: Adaptive Admission Control is disabled, using static request limits: maxConcurrentRequests: 50, maxPendingRequests: None.
26/01/05 09:09:47 WARN ExecutorServiceMetrics: Failed to bind as com.databricks.threading.InstrumentedScheduledThreadPoolExecutor is unsupported.
26/01/05 09:09:47 INFO DatabricksServerBuilder: Armeria server (ServerBackend, a.k.a. Phase 1) is created:
framework: ARMERIA
port: 6062
concurrency_conf {
  num_threads: 25
  max_concurrent_requests: 50
}
connection_conf {
  max_connection_age_ms: 3600000
}
request_conf {
  timeout_ms: 55000
  max_request_body_size_bytes: 1048576
}
framework_version: "1.30.3-r0"
max_header_list_size_bytes: 98304

26/01/05 09:09:47 INFO ReplDaemon: Created Armeria comm channel server
26/01/05 09:09:48 INFO JaegerHttpsExporter: Exporting Spans to unauthenticated https://jaeger-collector-privileged-worker.privileged.staging.dbns.databricks.com/api/traces?format=jaeger.thrift
26/01/05 09:09:48 INFO DatabricksTraceExporter: Trace exporter started... @ https://jaeger-collector-privileged-worker.privileged.staging.dbns.databricks.com/api/traces for service driver
26/01/05 09:09:48 INFO DatabricksTraceExporter: Tracing: Successfully enabled trace exporter
26/01/05 09:09:48 INFO NetstatUtil$: netstat -lnpt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 192.168.200.30:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8082          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8083          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8081          0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:12345           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:12345           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:12345           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:12345           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4318            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4316            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4317            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4315            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.34:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.34:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:39801         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.4:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.6:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5557            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5557            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5557            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5557            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:7073          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:7073          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:39835         0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:6000            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:39325         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.40:9878     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.40:9877     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:38809         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.10:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.10:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:46761         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.154:53          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:38345         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.32:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.32:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.28:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.28:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7778            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:45101         0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7769            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7898            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8686            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8687            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.5:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:44743         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:44689         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:44365         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:19001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:43773         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:35565         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:43739         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:35161         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.12:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.12:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.34:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.34:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.12:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.12:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10002         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10002         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:34811         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.32:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.32:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.3:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:42675         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9878          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9877          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9491          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9491          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:42459         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9666          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:34241         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:42101         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9313          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9410          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9410          0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:2813            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.14:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.14:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9202          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9202          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9206          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9206          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9204          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9204          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9205          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9205          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:50097         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8953          0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.14:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.14:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8910          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.4:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.4:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:41065         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:53            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.4:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.4:443           0.0.0.0:*               LISTEN      -                   
tcp6       0      0 127.0.0.1:40879         :::*                    LISTEN      1502/java           
tcp6       0      0 :::12306                :::*                    LISTEN      -                   
tcp6       0      0 :::5051                 :::*                    LISTEN      -                   
tcp6       0      0 :::22001                :::*                    LISTEN      -                   
tcp6       0      0 127.0.0.1:64031         :::*                    LISTEN      1502/java           
tcp6       0      0 10.152.169.53:39833     :::*                    LISTEN      1502/java           
tcp6       0      0 :::6060                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::6061                 :::*                    LISTEN      1502/java           
tcp6       0      0 :::6059                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7078                 :::*                    LISTEN      -                   
tcp6       0      0 :::7079                 :::*                    LISTEN      -                   
tcp6       0      0 :::7076                 :::*                    LISTEN      -                   
tcp6       0      0 :::7075                 :::*                    LISTEN      -                   
tcp6       0      0 :::7070                 :::*                    LISTEN      -                   
tcp6       0      0 :::7071                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7069                 :::*                    LISTEN      -                   
tcp6       0      0 10.152.169.53:38387     :::*                    LISTEN      1502/java           
tcp6       0      0 :::15002                :::*                    LISTEN      1502/java           
tcp6       0      0 127.0.0.1:62141         :::*                    LISTEN      1502/java           
tcp6       0      0 127.0.0.1:45713         :::*                    LISTEN      1502/java           
tcp6       0      0 127.0.0.1:37215         :::*                    LISTEN      1502/java           
tcp6       0      0 :::7945                 :::*                    LISTEN      -                   
tcp6       0      0 :::8002                 :::*                    LISTEN      -                   
tcp6       0      0 :::8003                 :::*                    LISTEN      -                   
tcp6       0      0 :::8000                 :::*                    LISTEN      -                   
tcp6       0      0 :::8001                 :::*                    LISTEN      -                   
tcp6       0      0 :::8085                 :::*                    LISTEN      -                   
tcp6       0      0 :::7776                 :::*                    LISTEN      -                   
tcp6       0      0 :::7777                 :::*                    LISTEN      -                   
tcp6       0      0 :::7788                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7789                 :::*                    LISTEN      1502/java           
tcp6       0      0 ::1:8953                :::*                    LISTEN      -                   
tcp6       0      0 127.0.0.1:4052          :::*                    LISTEN      -                   
tcp6       0      0 :::111                  :::*                    LISTEN      -                   
tcp6       0      0 :::9082                 :::*                    LISTEN      -                   
tcp6       0      0 :::9080                 :::*                    LISTEN      -                   
tcp6       0      0 :::9081                 :::*                    LISTEN      -                   
tcp6       0      0 :::9095                 :::*                    LISTEN      -                   
tcp6       0      0 :::9100                 :::*                    LISTEN      -                   
tcp6       0      0 :::1015                 :::*                    LISTEN      -                   
tcp6       0      0 :::1023                 :::*                    LISTEN      1502/java           
tcp6       0      0 :::1021                 :::*                    LISTEN      -                   
tcp6       0      0 :::1017                 :::*                    LISTEN      -                   
tcp6       0      0 :::8934                 :::*                    LISTEN      -                   
tcp6       0      0 :::8900                 :::*                    LISTEN      -                   
tcp6       0      0 :::9515                 :::*                    LISTEN      -                   
tcp6       0      0 :::1453                 :::*                    LISTEN      -                   
tcp6       0      0 :::9292                 :::*                    LISTEN      -                   
tcp6       0      0 :::9998                 :::*                    LISTEN      -                   
tcp6       0      0 :::9863                 :::*                    LISTEN      -                   
tcp6       0      0 :::10255                :::*                    LISTEN      -                   
tcp6       0      0 :::19094                :::*                    LISTEN      -                   
tcp6       0      0 :::19095                :::*                    LISTEN      -                   
tcp6       0      0 :::19093                :::*                    LISTEN      -                   
tcp6       0      0 :::19090                :::*                    LISTEN      -                   
tcp6       0      0 :::19091                :::*                    LISTEN      -                   
tcp6       0      0 :::19096                :::*                    LISTEN      -                   
tcp6       0      0 :::2813                 :::*                    LISTEN      -                   
tcp6       0      0 10.152.169.53:41616     :::*                    LISTEN      1502/java           
tcp6       0      0 127.0.0.1:49888         :::*                    LISTEN      1502/java           

26/01/05 09:09:48 INFO Server: Serving http at /10.152.169.53:6062
26/01/05 09:09:48 INFO ReplDaemon: Started comm channel server
26/01/05 09:09:48 INFO NetstatUtil$: netstat -lnpt
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 192.168.200.30:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8082          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8083          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8081          0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:12345           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:12345           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:12345           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:12345           0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4318            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4316            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4317            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:4315            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.34:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.34:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:39801         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.4:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.6:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5557            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5557            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5557            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:5557            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:7073          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:7073          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:39835         0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:6000            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:39325         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.40:9878     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.40:9877     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:38809         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.10:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.10:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.20:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:46761         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.154:53          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:38345         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.32:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.32:5432     0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.28:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.28:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8088            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7778            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:45101         0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7769            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:7898            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8686            0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:8687            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.5:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:111             0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:44743         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:44689         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:44365         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.24:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.30:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:19001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.10:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:43773         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.11:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:35565         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:43739         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:35161         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.12:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.12:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.34:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.34:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10248         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.12:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.12:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.3:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10002         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10002         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:10001         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:34811         0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.32:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.32:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.3:53        0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:42675         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9878          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9877          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9491          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9491          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:42459         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9666          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:34241         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:42101         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9313          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9410          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9410          0.0.0.0:*               LISTEN      -                   
tcp        0      0 0.0.0.0:2813            0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.14:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.14:80       0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9202          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9202          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9206          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9206          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9204          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9204          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9205          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:9205          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:50097         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8953          0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.14:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 192.168.200.14:443      0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:8910          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.4:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.4:80            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:80           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:41065         0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.1:53            0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.12:443          0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.4:443           0.0.0.0:*               LISTEN      -                   
tcp        0      0 127.0.0.4:443           0.0.0.0:*               LISTEN      -                   
tcp6       0      0 127.0.0.1:40879         :::*                    LISTEN      1502/java           
tcp6       0      0 :::12306                :::*                    LISTEN      -                   
tcp6       0      0 :::5051                 :::*                    LISTEN      -                   
tcp6       0      0 :::22001                :::*                    LISTEN      -                   
tcp6       0      0 127.0.0.1:64031         :::*                    LISTEN      1502/java           
tcp6       0      0 10.152.169.53:39833     :::*                    LISTEN      1502/java           
tcp6       0      0 :::6060                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::6061                 :::*                    LISTEN      1502/java           
tcp6       0      0 :::6059                 :::*                    LISTEN      1145/java           
tcp6       0      0 10.152.169.53:6062      :::*                    LISTEN      1502/java           
tcp6       0      0 :::7078                 :::*                    LISTEN      -                   
tcp6       0      0 :::7079                 :::*                    LISTEN      -                   
tcp6       0      0 :::7076                 :::*                    LISTEN      -                   
tcp6       0      0 :::7075                 :::*                    LISTEN      -                   
tcp6       0      0 :::7070                 :::*                    LISTEN      -                   
tcp6       0      0 :::7071                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7069                 :::*                    LISTEN      -                   
tcp6       0      0 10.152.169.53:38387     :::*                    LISTEN      1502/java           
tcp6       0      0 :::15002                :::*                    LISTEN      1502/java           
tcp6       0      0 127.0.0.1:62141         :::*                    LISTEN      1502/java           
tcp6       0      0 127.0.0.1:45713         :::*                    LISTEN      1502/java           
tcp6       0      0 127.0.0.1:37215         :::*                    LISTEN      1502/java           
tcp6       0      0 :::7945                 :::*                    LISTEN      -                   
tcp6       0      0 :::8002                 :::*                    LISTEN      -                   
tcp6       0      0 :::8003                 :::*                    LISTEN      -                   
tcp6       0      0 :::8000                 :::*                    LISTEN      -                   
tcp6       0      0 :::8001                 :::*                    LISTEN      -                   
tcp6       2      0 :::8085                 :::*                    LISTEN      -                   
tcp6       0      0 :::7776                 :::*                    LISTEN      -                   
tcp6       0      0 :::7777                 :::*                    LISTEN      -                   
tcp6       0      0 :::7788                 :::*                    LISTEN      1145/java           
tcp6       0      0 :::7789                 :::*                    LISTEN      1502/java           
tcp6       0      0 ::1:8953                :::*                    LISTEN      -                   
tcp6       0      0 127.0.0.1:4052          :::*                    LISTEN      -                   
tcp6       0      0 :::111                  :::*                    LISTEN      -                   
tcp6       0      0 :::9082                 :::*                    LISTEN      -                   
tcp6       0      0 :::9080                 :::*                    LISTEN      -                   
tcp6       0      0 :::9081                 :::*                    LISTEN      -                   
tcp6       0      0 :::9095                 :::*                    LISTEN      -                   
tcp6       0      0 :::9100                 :::*                    LISTEN      -                   
tcp6       0      0 :::1015                 :::*                    LISTEN      -                   
tcp6       0      0 :::1023                 :::*                    LISTEN      1502/java           
tcp6       0      0 :::1021                 :::*                    LISTEN      -                   
tcp6       0      0 :::1017                 :::*                    LISTEN      -                   
tcp6       0      0 :::8934                 :::*                    LISTEN      -                   
tcp6       0      0 :::8900                 :::*                    LISTEN      -                   
tcp6       0      0 :::9515                 :::*                    LISTEN      -                   
tcp6       0      0 :::1453                 :::*                    LISTEN      -                   
tcp6       0      0 :::9292                 :::*                    LISTEN      -                   
tcp6       0      0 :::9998                 :::*                    LISTEN      -                   
tcp6       0      0 :::9863                 :::*                    LISTEN      -                   
tcp6       0      0 :::10255                :::*                    LISTEN      -                   
tcp6       0      0 :::19094                :::*                    LISTEN      -                   
tcp6       0      0 :::19095                :::*                    LISTEN      -                   
tcp6       0      0 :::19093                :::*                    LISTEN      -                   
tcp6       0      0 :::19090                :::*                    LISTEN      -                   
tcp6       0      0 :::19091                :::*                    LISTEN      -                   
tcp6       0      0 :::19096                :::*                    LISTEN      -                   
tcp6       0      0 :::2813                 :::*                    LISTEN      -                   
tcp6       0      0 10.152.169.53:41616     :::*                    LISTEN      1502/java           
tcp6       0      0 127.0.0.1:49888         :::*                    LISTEN      1502/java           

26/01/05 09:09:48 INFO ReplDaemon$: REPL daemon started
26/01/05 09:09:51 INFO ReplManagerImpl: REPL ReplId-38f1a-322e1-cf7 finished addReplToExecutionContext (1)
26/01/05 09:09:51 INFO PythonReplFactory: Cold-start repl creation for: python, ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true)
26/01/05 09:09:51 INFO SessionUserManager$: Successfully created a user with ID 1007 for spark-5f3f7279-149f-42a7-821a-c5.
26/01/05 09:09:51 INFO ReplOuterWrapper: DriverWrapper created for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true)
26/01/05 09:09:51 INFO ReplManagerImpl: Adding repl ReplId-38f1a-322e1-cf7 to execution context session-2510101955956775-168989845438591 with Spark Connect session ID: Some(0d5931be-3a5b-4f76-911b-36a477270017) (2)
26/01/05 09:09:51 INFO ReplManagerImpl: StartReplOptions: 
26/01/05 09:09:51 INFO PythonDriverWrapper: REPL status transitioned to Starting ReplId-38f1a-322e1-cf7 (3)
26/01/05 09:09:51 INFO PythonDriverWrapper: Starting ReplId-38f1a-322e1-cf7 - driverStatus transitioned to Starting (4)
26/01/05 09:09:51 INFO JupyterDriverLocal: Setting up Python REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true), initializing JupyterDriverLocal (5 - 0)
26/01/05 09:09:52 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true)
26/01/05 09:09:52 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-38f1a-322e1-cf7
26/01/05 09:09:52 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
26/01/05 09:09:52 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true): started Py4J Gateway Server (5 - 1)
26/01/05 09:09:52 INFO VirtualenvCloneHelper: Creating Python notebook virtualenv for 5f3f7279-149f-42a7-821a-c5f3e0a84067 with user spark-5f3f7279-149f-42a7-821a-c5
26/01/05 09:09:52 INFO Utils: resolved command to be run: List(/bin/su, spark-5f3f7279-149f-42a7-821a-c5, -c, virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-5f3f7279-149f-42a7-821a-c5f3e0a84067 -p /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python --no-download --no-setuptools --no-wheel)
26/01/05 09:09:52 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-5f3f7279-149f-42a7-821a-c5f3e0a84067
26/01/05 09:09:52 INFO Utils: resolved command to be run: List(/bin/su, spark-5f3f7279-149f-42a7-821a-c5, -c, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python -c "import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs]))")
26/01/05 09:09:52 INFO Utils: resolved command to be run: List(/bin/su, spark-5f3f7279-149f-42a7-821a-c5, -c, /local_disk0/.ephemeral_nfs/envs/pythonEnv-5f3f7279-149f-42a7-821a-c5f3e0a84067/bin/python -c "from sysconfig import get_path; print(get_path('purelib'))")
26/01/05 09:09:52 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-5f3f7279-149f-42a7-821a-c5f3e0a84067/lib/python3.12/site-packages/sites.pth
26/01/05 09:09:52 INFO NotebookScopedPythonEnvManager: Time spent creating Python notebook virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-5f3f7279-149f-42a7-821a-c5f3e0a84067 is 657 ms
26/01/05 09:09:52 INFO NotebookScopedPythonEnvManager: Check environment isGPU: false
26/01/05 09:09:52 INFO JupyterDriverLocal: Created Python Environment Manager for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true) (5 - 2)
26/01/05 09:09:52 INFO JupyterDriverLocal: Created LSP backend symlink for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true) (5 - 3)
26/01/05 09:09:52 INFO JupyterDriverLocal: Sandbox API is not used in REPL
26/01/05 09:09:52 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-5f3f7279-149f-42a7-821a-c5f3e0a84067/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@70e09519 (5 current watcher(s)).
26/01/05 09:09:52 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-5f3f7279-149f-42a7-821a-c5f3e0a84067/python_start_notebook_scoped.sh, /databricks/spark/python/pyspark/wrapped_python.py, spark-5f3f7279-149f-42a7-821a-c5, /local_disk0/.ephemeral_nfs/envs/pythonEnv-5f3f7279-149f-42a7-821a-c5f3e0a84067/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/f8ad1c53a342b164541db05145414070af4d3512377e18f297d744d1560ce39e.json]
26/01/05 09:09:52 INFO IpykernelUtils$: Established and started ipyKernelProcess for REPL ReplId-38f1a-322e1-cf7 (5 - 4)
26/01/05 09:09:52 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process with ReplId=ReplId-38f1a-322e1-cf7 in repl cgroup
26/01/05 09:09:52 INFO IpykernelUtils$: Configured ipykernel stdout and stdin (5 - 5)
26/01/05 09:09:53 INFO IpykernelUtils$: Connection file updated for REPL ReplId-38f1a-322e1-cf7 (5 - 6)
26/01/05 09:09:53 INFO JupyterDriverLocal: iPykernel process started and configured for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true) (5 - 7)
26/01/05 09:09:53 INFO JupyterDriverLocal: Jupyter client and comm channels configured for repl ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true) (5 - 8)
26/01/05 09:09:53 INFO JupyterDriverLocal: Watchdog thread started for repl ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true) (5 - 9)
26/01/05 09:09:53 WARN LoggingService: [sreqId=e1fdbb9c, chanId=27a75349, raddr=127.0.0.1:59090, laddr=127.0.0.1:6061][h1c://ip-10-152-169-53/#POST] Request: {startTime=2026-01-05T09:09:53.494Z(1767604193494000), length=50B, duration=1968Âµs(1968866ns), scheme=ws+h1c, name=POST, headers=[:method=POST, :path=/?type="com.databricks.api.proto.chauffeur.GetSparkActiveJobInfoRequest", x-request-id=64f75a84-cb6f-4f70-86e1-20bb0f47ee06, content-length=50, content-type=application/octet-stream, traceparent=00-fefc09d4962f8c6132fc355f8d34f6ad-9f5d5fa336e9fafe-00]}
26/01/05 09:09:53 WARN LoggingService: [sreqId=e1fdbb9c, chanId=27a75349, raddr=127.0.0.1:59090, laddr=127.0.0.1:6061][h1c://ip-10-152-169-53/#POST] Response: {startTime=2026-01-05T09:09:53.509Z(1767604193509000), length=228B, duration=0ns, totalDuration=14962Âµs(14962310ns), cause=com.databricks.api.base.DatabricksServiceException: BAD_REQUEST: [SHOULD_USE_AUTOSCALING_INFO] , headers=[:status=500, content-length=228, content-type=application/octet-stream]}
com.databricks.api.base.DatabricksServiceException: BAD_REQUEST: [SHOULD_USE_AUTOSCALING_INFO] 
	at com.databricks.api.base.DatabricksServiceException$.apply(DatabricksServiceException.scala:464)
	at com.databricks.common.chauffeur.exception.ExceptionType.toDatabricksServiceException(ChauffeurException.scala:254)
	at com.databricks.common.chauffeur.exception.ChauffeurException$.shouldUseAutoscalingInfoException(ChauffeurException.scala:76)
	at com.databricks.backend.daemon.driver.DriverCorral.getSparkActiveJobInfo(DriverCorral.scala:1995)
	at com.databricks.backend.daemon.driver.DriverCorralCompatServerBackend.$anonfun$handlers$15(DriverCorralCompatServerBackend.scala:123)
	at com.databricks.rpc.armeria.JettyCompatibilityWrapperBlocking.$anonfun$unaryRpcHandler$1(CompatServerBackend.scala:473)
	at com.databricks.rpc.armeria.UnaryRpcHandler$.$anonfun$blocking$2(UnaryRpcHandler.scala:442)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$callFunc$2(UnaryRpcHandler.scala:314)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:84)
	at com.databricks.rpc.armeria.UnaryRpcHandler.callFunc(UnaryRpcHandler.scala:314)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.callFuncWithHooks(UnaryRpcHandler.scala:647)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.$anonfun$callFunc$3(UnaryRpcHandler.scala:625)
	at com.databricks.rpc.OperationSpan.$anonfun$wrapFuture$1(OperationSpan.scala:69)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.OperationSpan.withAttributionContext(OperationSpan.scala:22)
	at com.databricks.rpc.OperationSpan.wrapFuture(OperationSpan.scala:68)
	at com.databricks.rpc.armeria.UnaryRpcHandlerInternal.callFunc(UnaryRpcHandler.scala:623)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc0$3(UnaryRpcHandler.scala:274)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.armeria.UnaryRpcHandler.withAttributionContext(UnaryRpcHandler.scala:43)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc0$2(UnaryRpcHandler.scala:234)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleRpc0(UnaryRpcHandler.scala:234)
	at com.databricks.rpc.armeria.UnaryRpcHandler.$anonfun$handleRpc$1(UnaryRpcHandler.scala:205)
	at com.databricks.rpc.armeria.server.internal.RequestCompletionTracker.wrap(RequestCompletionTracker.scala:184)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleRpc(UnaryRpcHandler.scala:205)
	at com.databricks.rpc.armeria.UnaryRpcHandler.handleJettyRpc(UnaryRpcHandler.scala:88)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.handleJettyRpcWithAggregatedContent(UnaryRpcService.scala:522)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleContextAwareJettyRpcWithAggregatedContent$2(UnaryRpcService.scala:433)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.withAttributionContext(UnaryRpcService.scala:187)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleContextAwareJettyRpcWithAggregatedContent$1(UnaryRpcService.scala:428)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.handleContextAwareJettyRpcWithAggregatedContent(UnaryRpcService.scala:427)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleJettyJsonRpc$2(UnaryRpcService.scala:407)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:84)
	at com.databricks.rpc.armeria.Util$.handleUnexpectedExceptions(Util.scala:108)
	at com.databricks.rpc.armeria.UnaryRpcServiceInternal.$anonfun$handleJettyJsonRpc$1(UnaryRpcService.scala:402)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at com.databricks.threading.DatabricksExecutionContext$InstrumentedRunnable.run(DatabricksExecutionContext.scala:36)
	at grpc_shaded.com.linecorp.armeria.common.DefaultContextAwareRunnable.run(DefaultContextAwareRunnable.java:45)
	at com.databricks.threading.ContextBoundRunnable.$anonfun$run$2(ContextBoundRunnable.scala:16)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)
	at com.databricks.threading.ContextBoundRunnable.withAttributionContext(ContextBoundRunnable.scala:7)
	at com.databricks.threading.ContextBoundRunnable.$anonfun$run$1(ContextBoundRunnable.scala:16)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)
	at com.databricks.threading.ContextBoundRunnable.run(ContextBoundRunnable.scala:15)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$makeContextAware$2(InstrumentedExecutorService.scala:257)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$instrumentationWrapper$1(InstrumentedExecutorService.scala:299)
	at com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)
	at com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)
	at com.databricks.threading.InstrumentedExecutorService.trackActiveThreads(InstrumentedExecutorService.scala:72)
	at com.databricks.threading.InstrumentedExecutorService.instrumentationWrapper(InstrumentedExecutorService.scala:287)
	at com.databricks.threading.InstrumentedExecutorService.$anonfun$makeContextAware$1(InstrumentedExecutorService.scala:259)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
internalStackTrace: 
26/01/05 09:09:54 INFO JupyterDriverLocal: JupyterKernelListener instantiated and started for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true) (5 - 10)
26/01/05 09:09:54 INFO PythonDriverWrapper: Driver instantiated for ReplId-38f1a-322e1-cf7 (6)
26/01/05 09:09:54 INFO NotebookScopedPythonEnvManager: Pip metadata is empty, cleanup old pip configuration if exists
26/01/05 09:09:54 INFO PythonDriverWrapper: REPL started but is idle: ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true) (7)
26/01/05 09:09:54 INFO PythonDriverWrapper: setupRepl:ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true): finished to load
26/01/05 09:09:54 INFO PythonDriverWrapper: Finished setting-up REPL ReplId-38f1a-322e1-cf7, accepting commands (8)
26/01/05 09:09:54 INFO ProgressReporter$: Added result fetcher for 1001767603936503_6469837605990668936_run-168989845438591-ec-session-2510101955956775-168989845438591-list-libraries
26/01/05 09:09:54 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:09:54 +0000] "GET /metrics HTTP/1.1" 200 90362 
26/01/05 09:09:54 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:54 WARN WsfsHttpClient: Host http://databricks.node.host.local does not exist: java.net.UnknownHostException: databricks.node.host.local: Name or service not known
26/01/05 09:09:54 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:55 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:09:55 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(Mon Jan  5 09:09:53 2026 Connection to spark from PID  3584
Mon Jan  5 09:09:53 2026 Initialized gateway on port 42671
Mon Jan  5 09:09:53 2026 Connected to spark.
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:55 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_6469837605990668936_run-168989845438591-ec-session-2510101955956775-168989845438591-list-libraries
26/01/05 09:09:55 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_6469837605990668936_run-168989845438591-ec-session-2510101955956775-168989845438591-list-libraries
26/01/05 09:09:55 INFO ProgressReporter$: Added result fetcher for 1001767603936503_7722644750583471115_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:55 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:55 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:55 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_7722644750583471115_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:55 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_7722644750583471115_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:55 INFO ProgressReporter$: Added result fetcher for 1001767603936503_5907855750726074189_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:55 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:55 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:56 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_5907855750726074189_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:56 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_5907855750726074189_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:56 INFO ProgressReporter$: Added result fetcher for 1001767603936503_7094800664014790181_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:56 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:56 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:56 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:09:56,346 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:56 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_7094800664014790181_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:56 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_7094800664014790181_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:56 INFO ProgressReporter$: Added result fetcher for 1001767603936503_9206063408600544867_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:56 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:56 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:56 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:09:56,633 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:56 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_9206063408600544867_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:56 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_9206063408600544867_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:57 INFO ProgressReporter$: Added result fetcher for 1001767603936503_7264994873213894205_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:57 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:09:57,116 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:57 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_7264994873213894205_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:57 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_7264994873213894205_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:57 INFO SharedState: Scheduler stats enabled.
26/01/05 09:09:57 INFO DriverResourceMonitor: Driver resource monitor is disabled.
26/01/05 09:09:57 INFO DriverCapacity: Starting DriverCapacity trackers
26/01/05 09:09:57 INFO MemoryUsageTracker: Starting MemoryUsageTracker
26/01/05 09:09:57 INFO DriverCapacity: Creating DriverMemoryCapacity
26/01/05 09:09:57 INFO DriverCapacity: Creating DriverCpuCapacity
26/01/05 09:09:57 INFO ProgressReporter$: Added result fetcher for 1001767603936503_4936619689737192664_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:57 INFO ObservedStatsStore: ObservedStatsStoreSoftstorePredictionBackend initialization skipped because the orgId is not set yet.
26/01/05 09:09:57 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
26/01/05 09:09:57 INFO SharedState: Warehouse path is 'dbfs:/user/hive/warehouse'.
26/01/05 09:09:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@cc9dc7a{/storage/iocache,null,AVAILABLE,@Spark}
26/01/05 09:09:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@144e9f3d{/storage/iocache/json,null,AVAILABLE,@Spark}
26/01/05 09:09:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a0d62e4{/SQL,null,AVAILABLE,@Spark}
26/01/05 09:09:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@294c9cea{/SQL/json,null,AVAILABLE,@Spark}
26/01/05 09:09:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2a9c6a5b{/SQL/execution,null,AVAILABLE,@Spark}
26/01/05 09:09:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@329fba68{/SQL/execution/json,null,AVAILABLE,@Spark}
26/01/05 09:09:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@71ab9911{/static/sql,null,AVAILABLE,@Spark}
26/01/05 09:09:57 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:09:57,610 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:57 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
26/01/05 09:09:57 WARN SQLConf: The SQL config 'spark.sql.hive.convertCTAS' has been deprecated in Spark v3.1 and may be removed in the future. Set 'spark.sql.legacy.createHiveTableByDefault' to false instead.
26/01/05 09:09:57 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_4936619689737192664_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:57 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_4936619689737192664_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:57 INFO ProgressReporter$: Added result fetcher for 1001767603936503_5480036549785324416_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:57 WARN DatabricksEdge: org.apache.spark.sql.sources.DataSourceRegister: com.google.cloud.spark.bigquery.BigQueryRelationProvider Unable to get public no-arg constructor
26/01/05 09:09:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:57 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:09:57,956 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:58 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_5480036549785324416_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_5480036549785324416_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO ProgressReporter$: Added result fetcher for 1001767603936503_7028724864734024943_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:58 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:58 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:09:58,325 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:58 INFO UnifiedSoftstore: [UnifiedSoftstore]: Initializing unified softstore syncer and keylib asynchronously.
26/01/05 09:09:58 INFO UnifiedSoftstore: [UnifiedSoftstore]: clusterId not defined, cannot initialize.
26/01/05 09:09:58 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_7028724864734024943_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_7028724864734024943_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO ProgressReporter$: Added result fetcher for 1001767603936503_5487343582896264991_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:58 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:58 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:09:58,695 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:58 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_5487343582896264991_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_5487343582896264991_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO ProgressReporter$: Added result fetcher for 1001767603936503_5776986236684519563_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:09:58 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:58 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:09:59 INFO NativeAzureFileSystem: WASB Filesystem null is closed with isClosed = false
26/01/05 09:09:59 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:09:59,017 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:09:59 INFO MemoryUsageTracker: GC notification:
 Name: PS Scavenge,
 Action: end of minor GC,
 Cause: Allocation Failure
 StartTime: 336519
 Duration: 46
26/01/05 09:09:59 INFO DatabricksMountsStore: Mount store initialization: Attempting to get the list of mounts from metadata manager of DBFS
26/01/05 09:09:59 INFO ProgressReporter$: Reporting partial results for running commands: 1001767603936503_5776986236684519563_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:10:01 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:10:01 +0000] "GET /metrics HTTP/1.1" 200 94276 
26/01/05 09:10:03 INFO DatabricksMountsStore: Mount store initialization: Received a list of 4 mounts accessible from metadata manager of DBFS
26/01/05 09:10:03 INFO DatabricksMountsStore: Updated mounts cache. Changes: List((+,DbfsMountPoint(s3a://databricks-datasets-ohio/, /databricks-datasets)), (+,DbfsMountPoint(uc-volumes:/Volumes, /Volumes)), (+,DbfsMountPoint(workspace-filesystem:/Workspace, /Workspace)), (+,DbfsMountPoint(disableddbfs://host-placeholder/, /)))
26/01/05 09:10:03 INFO DbfsHadoop3: Initialized DBFS with DBFSV2 as the delegate.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3n. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme wasbs. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme gs. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme s3a. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme r2. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme abfss. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme abfs. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 INFO HadoopFSUtil$: Installing the old filesystem implementation for scheme wasb. Current value: com.databricks.sql.acl.fs.CredentialScopeFileSystem. Old value to be restored: com.databricks.sql.io.LokiFileSystem.
26/01/05 09:10:04 WARN DisabledDatabricksFileSystem: [getFileStatus] Public DBFS root is disabled. Access is denied on path: /
26/01/05 09:10:04 INFO DriverCorral: DBFS health check ok (DBFS root disabled)
26/01/05 09:10:34 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_5776986236684519563_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:10:34 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_5776986236684519563_org-2510101955956775-job-359180529947007-run-168989845438591-action-7366780323428787
26/01/05 09:10:34 INFO ProgressReporter$: Added result fetcher for 1001767603936503_6584966740179595545_run-168989845438591-ec-session-2510101955956775-168989845438591-retreive-library-info
26/01/05 09:10:34 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:10:34 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:10:34 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:10:34 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_6584966740179595545_run-168989845438591-ec-session-2510101955956775-168989845438591-retreive-library-info
26/01/05 09:10:34 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_6584966740179595545_run-168989845438591-ec-session-2510101955956775-168989845438591-retreive-library-info
26/01/05 09:10:35 INFO ProgressReporter$: Added result fetcher for 1001767603936503_7652590661023669355_run-168989845438591-ec-session-2510101955956775-168989845438591-retrieve-dbr-runtime-info
26/01/05 09:10:35 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:10:35 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:10:35 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:10:36 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_7652590661023669355_run-168989845438591-ec-session-2510101955956775-168989845438591-retrieve-dbr-runtime-info
26/01/05 09:10:36 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_7652590661023669355_run-168989845438591-ec-session-2510101955956775-168989845438591-retrieve-dbr-runtime-info
26/01/05 09:10:38 INFO ProgressReporter$: Added result fetcher for 1001767603936503_5373738113661659759_run-168989845438591-ec-session-2510101955956775-168989845438591-release-spark-session
26/01/05 09:10:38 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:10:38 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3584): time:[4026531834]
26/01/05 09:10:38 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:10:39 INFO ProgressReporter$: Removed result fetcher for 1001767603936503_5373738113661659759_run-168989845438591-ec-session-2510101955956775-168989845438591-release-spark-session
26/01/05 09:10:39 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936503_5373738113661659759_run-168989845438591-ec-session-2510101955956775-168989845438591-release-spark-session
26/01/05 09:10:41 WARN PythonLoggingImpl: [Repl Driver Id: ReplId-38f1a-322e1-cf7] Keepalive failure. This may represent a transient network error reaching the Spark server.
Traceback (most recent call last):
  File "/databricks/python_shell/lib/dbruntime/serverless/keepalive.py", line 124, in _send_single_keepalive
    self._spark_version_request(client, spark)
  File "/databricks/python_shell/lib/dbruntime/serverless/keepalive.py", line 109, in _spark_version_request
    spark_version_response = client._stub.AnalyzePlan(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 277, in __call__
    response, ignored_call = self._with_call(
                             ^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 332, in _with_call
    return call.result(), call
           ^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_channel.py", line 440, in result
    raise self
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 315, in continuation
    response, call = self._thunk(new_method).with_call(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 343, in with_call
    return self._with_call(
           ^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 332, in _with_call
    return call.result(), call
           ^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_channel.py", line 440, in result
    raise self
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 315, in continuation
    response, call = self._thunk(new_method).with_call(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_channel.py", line 1198, in with_call
    return _end_unary_response_blocking(state, call, True, None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_channel.py", line 1006, in _end_unary_response_blocking
    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:
	status = StatusCode.INTERNAL
	details = "[INVALID_HANDLE.SESSION_CLOSED] The handle 0d5931be-3a5b-4f76-911b-36a477270017 is invalid. Session was closed. SQLSTATE: HY000"
	debug_error_string = "UNKNOWN:Error received from peer  {created_time:"2026-01-05T09:10:41.35572205+00:00", grpc_status:13, grpc_message:"[INVALID_HANDLE.SESSION_CLOSED] The handle 0d5931be-3a5b-4f76-911b-36a477270017 is invalid. Session was closed. SQLSTATE: HY000"}"
>


26/01/05 09:10:42 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:10:42 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:10:42 INFO ReplCrashUtils$: python shell exit code: 143; replId: ReplId-38f1a-322e1-cf7, pid: 3584
26/01/05 09:10:42 INFO PythonDriverWrapper: Stopping main loop for REPL ReplId-38f1a-322e1-cf7
26/01/05 09:10:42 INFO ReplManagerImpl: ReplInfo(driverReplId=ReplId-38f1a-322e1-cf7, chauffeurReplId=ReplId-38f1a-322e1-cf7,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-168989845438591)), lazyInfoInitialized=true) successfully discarded
26/01/05 09:10:42 WARN SessionUserManager$: Fail to kill all processes by user spark-5f3f7279-149f-42a7-821a-c5, ret code: 1, errMsg: Cannot find user spark-5f3f7279-149f-42a7-821a-c5

26/01/05 09:10:43 INFO ReplManagerImpl: REPL ReplId-38f1a-322e1-cf8 finished addReplToExecutionContext (1)
26/01/05 09:10:43 INFO PythonReplFactory: Cold-start repl creation for: python, ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true)
26/01/05 09:10:44 INFO SessionUserManager$: Successfully created a user with ID 1008 for spark-98d0c60c-f633-46e5-9ace-ec.
26/01/05 09:10:44 INFO ReplOuterWrapper: DriverWrapper created for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true)
26/01/05 09:10:44 INFO ReplManagerImpl: Adding repl ReplId-38f1a-322e1-cf8 to execution context session-2510101955956775-554945470126860 with Spark Connect session ID: Some(f27dcae4-07ee-40e1-b2bb-8ee0675dc82f) (2)
26/01/05 09:10:44 INFO ReplManagerImpl: StartReplOptions: 
26/01/05 09:10:44 INFO PythonDriverWrapper: REPL status transitioned to Starting ReplId-38f1a-322e1-cf8 (3)
26/01/05 09:10:44 INFO PythonDriverWrapper: Starting ReplId-38f1a-322e1-cf8 - driverStatus transitioned to Starting (4)
26/01/05 09:10:44 INFO JupyterDriverLocal: Setting up Python REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true), initializing JupyterDriverLocal (5 - 0)
26/01/05 09:10:44 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true)
26/01/05 09:10:44 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-38f1a-322e1-cf8
26/01/05 09:10:44 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
26/01/05 09:10:44 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true): started Py4J Gateway Server (5 - 1)
26/01/05 09:10:44 INFO VirtualenvCloneHelper: Creating Python notebook virtualenv for 98d0c60c-f633-46e5-9ace-ec4abe0e48d1 with user spark-98d0c60c-f633-46e5-9ace-ec
26/01/05 09:10:44 INFO Utils: resolved command to be run: List(/bin/su, spark-98d0c60c-f633-46e5-9ace-ec, -c, virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-98d0c60c-f633-46e5-9ace-ec4abe0e48d1 -p /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python --no-download --no-setuptools --no-wheel)
26/01/05 09:10:45 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-98d0c60c-f633-46e5-9ace-ec4abe0e48d1
26/01/05 09:10:45 INFO Utils: resolved command to be run: List(/bin/su, spark-98d0c60c-f633-46e5-9ace-ec, -c, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python -c "import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs]))")
26/01/05 09:10:45 INFO Utils: resolved command to be run: List(/bin/su, spark-98d0c60c-f633-46e5-9ace-ec, -c, /local_disk0/.ephemeral_nfs/envs/pythonEnv-98d0c60c-f633-46e5-9ace-ec4abe0e48d1/bin/python -c "from sysconfig import get_path; print(get_path('purelib'))")
26/01/05 09:10:45 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-98d0c60c-f633-46e5-9ace-ec4abe0e48d1/lib/python3.12/site-packages/sites.pth
26/01/05 09:10:45 INFO NotebookScopedPythonEnvManager: Time spent creating Python notebook virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-98d0c60c-f633-46e5-9ace-ec4abe0e48d1 is 562 ms
26/01/05 09:10:45 INFO NotebookScopedPythonEnvManager: Check environment isGPU: false
26/01/05 09:10:45 INFO JupyterDriverLocal: Created Python Environment Manager for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true) (5 - 2)
26/01/05 09:10:45 INFO JupyterDriverLocal: Created LSP backend symlink for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true) (5 - 3)
26/01/05 09:10:45 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-98d0c60c-f633-46e5-9ace-ec4abe0e48d1/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@768c2d88 (5 current watcher(s)).
26/01/05 09:10:45 INFO JupyterDriverLocal: Sandbox API is not used in REPL
26/01/05 09:10:45 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-98d0c60c-f633-46e5-9ace-ec4abe0e48d1/python_start_notebook_scoped.sh, /databricks/spark/python/pyspark/wrapped_python.py, spark-98d0c60c-f633-46e5-9ace-ec, /local_disk0/.ephemeral_nfs/envs/pythonEnv-98d0c60c-f633-46e5-9ace-ec4abe0e48d1/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/54cd04c79b242503e25d99b965ab65cb2b3158b64e5efd4c94d47d0c018a47c6.json]
26/01/05 09:10:45 INFO IpykernelUtils$: Established and started ipyKernelProcess for REPL ReplId-38f1a-322e1-cf8 (5 - 4)
26/01/05 09:10:45 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process with ReplId=ReplId-38f1a-322e1-cf8 in repl cgroup
26/01/05 09:10:45 INFO IpykernelUtils$: Configured ipykernel stdout and stdin (5 - 5)
26/01/05 09:10:46 INFO IpykernelUtils$: Connection file updated for REPL ReplId-38f1a-322e1-cf8 (5 - 6)
26/01/05 09:10:46 INFO JupyterDriverLocal: iPykernel process started and configured for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true) (5 - 7)
26/01/05 09:10:46 INFO JupyterDriverLocal: Jupyter client and comm channels configured for repl ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true) (5 - 8)
26/01/05 09:10:46 INFO JupyterDriverLocal: Watchdog thread started for repl ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true) (5 - 9)
26/01/05 09:10:46 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:10:46 +0000] "GET /metrics HTTP/1.1" 200 97793 
26/01/05 09:10:46 INFO JupyterDriverLocal: JupyterKernelListener instantiated and started for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true) (5 - 10)
26/01/05 09:10:46 INFO PythonDriverWrapper: Driver instantiated for ReplId-38f1a-322e1-cf8 (6)
26/01/05 09:10:46 INFO NotebookScopedPythonEnvManager: Pip metadata is empty, cleanup old pip configuration if exists
26/01/05 09:10:46 INFO PythonDriverWrapper: REPL started but is idle: ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true) (7)
26/01/05 09:10:46 INFO PythonDriverWrapper: setupRepl:ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true): finished to load
26/01/05 09:10:46 INFO PythonDriverWrapper: Finished setting-up REPL ReplId-38f1a-322e1-cf8, accepting commands (8)
26/01/05 09:10:47 INFO ProgressReporter$: Added result fetcher for 1001767603936504_8907123763464849669_run-554945470126860-ec-session-2510101955956775-554945470126860-list-libraries
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 WARN WsfsHttpClient: Host http://databricks.node.host.local does not exist: java.net.UnknownHostException: databricks.node.host.local: Name or service not known
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:10:47 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(Mon Jan  5 09:10:46 2026 Connection to spark from PID  3886
Mon Jan  5 09:10:46 2026 Initialized gateway on port 34899
Mon Jan  5 09:10:46 2026 Connected to spark.
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:10:47 INFO ProgressReporter$: [82 occurrences] Reporting progress for running commands: 1001767603936504_8907123763464849669_run-554945470126860-ec-session-2510101955956775-554945470126860-list-libraries
26/01/05 09:10:47 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_8907123763464849669_run-554945470126860-ec-session-2510101955956775-554945470126860-list-libraries
26/01/05 09:10:47 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_8907123763464849669_run-554945470126860-ec-session-2510101955956775-554945470126860-list-libraries
26/01/05 09:10:47 INFO ProgressReporter$: Added result fetcher for 1001767603936504_6251877067031749061_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_6251877067031749061_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_6251877067031749061_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO ProgressReporter$: Added result fetcher for 1001767603936504_5126452094957300964_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_5126452094957300964_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_5126452094957300964_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO ProgressReporter$: Added result fetcher for 1001767603936504_8882384325793542555_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:10:47,654 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:10:47 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_8882384325793542555_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_8882384325793542555_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO ProgressReporter$: Added result fetcher for 1001767603936504_6682621165169626161_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:10:47,787 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:10:47 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_6682621165169626161_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_6682621165169626161_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO ProgressReporter$: Added result fetcher for 1001767603936504_5208234453773160404_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:47 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:10:47,969 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:10:48 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_5208234453773160404_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:48 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_5208234453773160404_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:48 INFO ProgressReporter$: Added result fetcher for 1001767603936504_5162513351849211735_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:48 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:48 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:48 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:10:48,214 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:10:48 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_5162513351849211735_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:48 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_5162513351849211735_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:48 INFO ProgressReporter$: Added result fetcher for 1001767603936504_4658972285582376206_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:48 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:48 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:48 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(2026-01-05 09:10:48,399 - INFO - Received command c on object id p0
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:10:50 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_4658972285582376206_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:50 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_4658972285582376206_org-2510101955956775-job-359180529947007-run-554945470126860-action-720802798278076
26/01/05 09:10:50 INFO ProgressReporter$: Added result fetcher for 1001767603936504_6424135553908834571_run-554945470126860-ec-session-2510101955956775-554945470126860-retreive-library-info
26/01/05 09:10:50 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:50 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:50 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:10:51 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_6424135553908834571_run-554945470126860-ec-session-2510101955956775-554945470126860-retreive-library-info
26/01/05 09:10:51 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_6424135553908834571_run-554945470126860-ec-session-2510101955956775-554945470126860-retreive-library-info
26/01/05 09:10:53 INFO ProgressReporter$: Added result fetcher for 1001767603936504_8796687193916946504_run-554945470126860-ec-session-2510101955956775-554945470126860-retrieve-dbr-runtime-info
26/01/05 09:10:53 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:53 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:53 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:10:54 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:10:53 +0000] "GET /metrics HTTP/1.1" 200 97806 
26/01/05 09:10:54 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_8796687193916946504_run-554945470126860-ec-session-2510101955956775-554945470126860-retrieve-dbr-runtime-info
26/01/05 09:10:54 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_8796687193916946504_run-554945470126860-ec-session-2510101955956775-554945470126860-retrieve-dbr-runtime-info
26/01/05 09:10:56 INFO ProgressReporter$: Added result fetcher for 1001767603936504_5303294051646370593_run-554945470126860-ec-session-2510101955956775-554945470126860-release-spark-session
26/01/05 09:10:56 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:56 INFO LocalFuseProcess: Time namespace for current process (registered process pid=3886): time:[4026531834]
26/01/05 09:10:56 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:10:57 INFO ProgressReporter$: Removed result fetcher for 1001767603936504_5303294051646370593_run-554945470126860-ec-session-2510101955956775-554945470126860-release-spark-session
26/01/05 09:10:57 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936504_5303294051646370593_run-554945470126860-ec-session-2510101955956775-554945470126860-release-spark-session
26/01/05 09:11:00 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:11:00 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:11:00 INFO ReplCrashUtils$: python shell exit code: 143; replId: ReplId-38f1a-322e1-cf8, pid: 3886
26/01/05 09:11:00 INFO PythonDriverWrapper: Stopping main loop for REPL ReplId-38f1a-322e1-cf8
26/01/05 09:11:00 INFO ReplManagerImpl: ReplInfo(driverReplId=ReplId-38f1a-322e1-cf8, chauffeurReplId=ReplId-38f1a-322e1-cf8,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-554945470126860)), lazyInfoInitialized=true) successfully discarded
26/01/05 09:11:00 WARN SessionUserManager$: Fail to kill all processes by user spark-98d0c60c-f633-46e5-9ace-ec, ret code: 1, errMsg: Cannot find user spark-98d0c60c-f633-46e5-9ace-ec

26/01/05 09:11:01 INFO ReplManagerImpl: REPL ReplId-38f1a-322e1-cf9 finished addReplToExecutionContext (1)
26/01/05 09:11:01 INFO PythonReplFactory: Cold-start repl creation for: python, ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true)
26/01/05 09:11:02 INFO SessionUserManager$: Successfully created a user with ID 1009 for spark-dc176015-7248-4262-8bcd-d4.
26/01/05 09:11:02 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:11:02 +0000] "GET /metrics HTTP/1.1" 200 97776 
26/01/05 09:11:02 INFO ReplOuterWrapper: DriverWrapper created for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true)
26/01/05 09:11:02 INFO ReplManagerImpl: Adding repl ReplId-38f1a-322e1-cf9 to execution context session-2510101955956775-987305543573757 with Spark Connect session ID: Some(f216af12-8b5a-4081-944a-57cfc9c9fdaf) (2)
26/01/05 09:11:02 INFO ReplManagerImpl: StartReplOptions: 
26/01/05 09:11:02 INFO PythonDriverWrapper: REPL status transitioned to Starting ReplId-38f1a-322e1-cf9 (3)
26/01/05 09:11:02 INFO PythonDriverWrapper: Starting ReplId-38f1a-322e1-cf9 - driverStatus transitioned to Starting (4)
26/01/05 09:11:02 INFO JupyterDriverLocal: Setting up Python REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true), initializing JupyterDriverLocal (5 - 0)
26/01/05 09:11:02 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true)
26/01/05 09:11:02 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-38f1a-322e1-cf9
26/01/05 09:11:02 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
26/01/05 09:11:02 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true): started Py4J Gateway Server (5 - 1)
26/01/05 09:11:02 INFO VirtualenvCloneHelper: Creating Python notebook virtualenv for dc176015-7248-4262-8bcd-d40ab9a869f0 with user spark-dc176015-7248-4262-8bcd-d4
26/01/05 09:11:02 INFO Utils: resolved command to be run: List(/bin/su, spark-dc176015-7248-4262-8bcd-d4, -c, virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-dc176015-7248-4262-8bcd-d40ab9a869f0 -p /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python --no-download --no-setuptools --no-wheel)
26/01/05 09:11:03 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-dc176015-7248-4262-8bcd-d40ab9a869f0
26/01/05 09:11:03 INFO Utils: resolved command to be run: List(/bin/su, spark-dc176015-7248-4262-8bcd-d4, -c, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python -c "import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs]))")
26/01/05 09:11:03 INFO Utils: resolved command to be run: List(/bin/su, spark-dc176015-7248-4262-8bcd-d4, -c, /local_disk0/.ephemeral_nfs/envs/pythonEnv-dc176015-7248-4262-8bcd-d40ab9a869f0/bin/python -c "from sysconfig import get_path; print(get_path('purelib'))")
26/01/05 09:11:03 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-dc176015-7248-4262-8bcd-d40ab9a869f0/lib/python3.12/site-packages/sites.pth
26/01/05 09:11:03 INFO NotebookScopedPythonEnvManager: Time spent creating Python notebook virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-dc176015-7248-4262-8bcd-d40ab9a869f0 is 625 ms
26/01/05 09:11:03 INFO NotebookScopedPythonEnvManager: Check environment isGPU: false
26/01/05 09:11:03 INFO JupyterDriverLocal: Created Python Environment Manager for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true) (5 - 2)
26/01/05 09:11:03 INFO JupyterDriverLocal: Created LSP backend symlink for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true) (5 - 3)
26/01/05 09:11:03 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-dc176015-7248-4262-8bcd-d40ab9a869f0/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@512cace4 (5 current watcher(s)).
26/01/05 09:11:03 INFO JupyterDriverLocal: Sandbox API is not used in REPL
26/01/05 09:11:03 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-dc176015-7248-4262-8bcd-d40ab9a869f0/python_start_notebook_scoped.sh, /databricks/spark/python/pyspark/wrapped_python.py, spark-dc176015-7248-4262-8bcd-d4, /local_disk0/.ephemeral_nfs/envs/pythonEnv-dc176015-7248-4262-8bcd-d40ab9a869f0/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/fb965b469f1b6364b2461f6506d3e38a090d9db962d0eb88dca2a4da65797558.json]
26/01/05 09:11:03 INFO IpykernelUtils$: Established and started ipyKernelProcess for REPL ReplId-38f1a-322e1-cf9 (5 - 4)
26/01/05 09:11:03 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process with ReplId=ReplId-38f1a-322e1-cf9 in repl cgroup
26/01/05 09:11:03 INFO IpykernelUtils$: Configured ipykernel stdout and stdin (5 - 5)
26/01/05 09:11:04 INFO IpykernelUtils$: Connection file updated for REPL ReplId-38f1a-322e1-cf9 (5 - 6)
26/01/05 09:11:04 INFO JupyterDriverLocal: iPykernel process started and configured for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true) (5 - 7)
26/01/05 09:11:04 INFO JupyterDriverLocal: Jupyter client and comm channels configured for repl ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true) (5 - 8)
26/01/05 09:11:04 INFO JupyterDriverLocal: Watchdog thread started for repl ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true) (5 - 9)
26/01/05 09:11:04 INFO JupyterDriverLocal: JupyterKernelListener instantiated and started for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true) (5 - 10)
26/01/05 09:11:04 INFO PythonDriverWrapper: Driver instantiated for ReplId-38f1a-322e1-cf9 (6)
26/01/05 09:11:04 INFO NotebookScopedPythonEnvManager: Pip metadata is empty, cleanup old pip configuration if exists
26/01/05 09:11:04 INFO PythonDriverWrapper: REPL started but is idle: ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true) (7)
26/01/05 09:11:04 INFO PythonDriverWrapper: setupRepl:ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true): finished to load
26/01/05 09:11:04 INFO PythonDriverWrapper: Finished setting-up REPL ReplId-38f1a-322e1-cf9, accepting commands (8)
26/01/05 09:11:05 INFO ProgressReporter$: Added result fetcher for 1001767603936505_8793842226257548907_run-987305543573757-ec-session-2510101955956775-987305543573757-list-libraries
26/01/05 09:11:05 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:05 WARN WsfsHttpClient: Host http://databricks.node.host.local does not exist: java.net.UnknownHostException: databricks.node.host.local: Name or service not known
26/01/05 09:11:05 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:05 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:11:05 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(Mon Jan  5 09:11:04 2026 Connection to spark from PID  4080
Mon Jan  5 09:11:04 2026 Initialized gateway on port 33265
Mon Jan  5 09:11:04 2026 Connected to spark.
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:11:05 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_8793842226257548907_run-987305543573757-ec-session-2510101955956775-987305543573757-list-libraries
26/01/05 09:11:05 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_8793842226257548907_run-987305543573757-ec-session-2510101955956775-987305543573757-list-libraries
26/01/05 09:11:05 INFO ProgressReporter$: Added result fetcher for 1001767603936505_7908954335815517886_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:05 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:05 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:11 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_7908954335815517886_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:11 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_7908954335815517886_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:11 INFO ProgressReporter$: Added result fetcher for 1001767603936505_5257616863169308732_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:11 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:11 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:11 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_5257616863169308732_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:11 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_5257616863169308732_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:11 INFO ProgressReporter$: Added result fetcher for 1001767603936505_5575144394461253990_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:11 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:11 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:13 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_5575144394461253990_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:13 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_5575144394461253990_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:13 INFO ProgressReporter$: Added result fetcher for 1001767603936505_6335300762958153382_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:13 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:13 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:13 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_6335300762958153382_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:13 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_6335300762958153382_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:14 INFO ProgressReporter$: Added result fetcher for 1001767603936505_7884153150601448687_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:14 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:14 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:14 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_7884153150601448687_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:14 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_7884153150601448687_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:14 INFO ProgressReporter$: Added result fetcher for 1001767603936505_7334168980175793308_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:14 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:14 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:15 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_7334168980175793308_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:15 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_7334168980175793308_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:15 INFO ProgressReporter$: Added result fetcher for 1001767603936505_5742073283822197508_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:15 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:15 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:16 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_5742073283822197508_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:16 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_5742073283822197508_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:16 INFO ProgressReporter$: Added result fetcher for 1001767603936505_6832832994032118393_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:16 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:16 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:17 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_6832832994032118393_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:17 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_6832832994032118393_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:17 INFO ProgressReporter$: Added result fetcher for 1001767603936505_6257450427702250223_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:17 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:17 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:31 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:11:31 +0000] "GET /metrics HTTP/1.1" 200 98284 
26/01/05 09:11:32 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_6257450427702250223_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:32 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_6257450427702250223_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:32 INFO ProgressReporter$: Added result fetcher for 1001767603936505_7111730821784823107_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:32 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:32 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:44 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_7111730821784823107_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:44 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_7111730821784823107_org-2510101955956775-job-359180529947007-run-987305543573757-action-4774921352589515
26/01/05 09:11:44 INFO ProgressReporter$: Added result fetcher for 1001767603936505_7825078151709426737_run-987305543573757-ec-session-2510101955956775-987305543573757-retreive-library-info
26/01/05 09:11:44 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:44 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:44 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:11:44 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_7825078151709426737_run-987305543573757-ec-session-2510101955956775-987305543573757-retreive-library-info
26/01/05 09:11:44 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_7825078151709426737_run-987305543573757-ec-session-2510101955956775-987305543573757-retreive-library-info
26/01/05 09:11:46 INFO ProgressReporter$: Added result fetcher for 1001767603936505_4886808167488651739_run-987305543573757-ec-session-2510101955956775-987305543573757-retrieve-dbr-runtime-info
26/01/05 09:11:46 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:46 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:46 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:11:46 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_4886808167488651739_run-987305543573757-ec-session-2510101955956775-987305543573757-retrieve-dbr-runtime-info
26/01/05 09:11:46 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_4886808167488651739_run-987305543573757-ec-session-2510101955956775-987305543573757-retrieve-dbr-runtime-info
26/01/05 09:11:49 INFO ProgressReporter$: Added result fetcher for 1001767603936505_7509357689705872515_run-987305543573757-ec-session-2510101955956775-987305543573757-release-spark-session
26/01/05 09:11:49 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:49 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4080): time:[4026531834]
26/01/05 09:11:49 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:11:49 INFO ProgressReporter$: Removed result fetcher for 1001767603936505_7509357689705872515_run-987305543573757-ec-session-2510101955956775-987305543573757-release-spark-session
26/01/05 09:11:49 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936505_7509357689705872515_run-987305543573757-ec-session-2510101955956775-987305543573757-release-spark-session
26/01/05 09:11:50 WARN PythonLoggingImpl: [Repl Driver Id: ReplId-38f1a-322e1-cf9] Keepalive failure. This may represent a transient network error reaching the Spark server.
Traceback (most recent call last):
  File "/databricks/python_shell/lib/dbruntime/serverless/keepalive.py", line 124, in _send_single_keepalive
    self._spark_version_request(client, spark)
  File "/databricks/python_shell/lib/dbruntime/serverless/keepalive.py", line 109, in _spark_version_request
    spark_version_response = client._stub.AnalyzePlan(
                             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 277, in __call__
    response, ignored_call = self._with_call(
                             ^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 332, in _with_call
    return call.result(), call
           ^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_channel.py", line 440, in result
    raise self
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 315, in continuation
    response, call = self._thunk(new_method).with_call(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 343, in with_call
    return self._with_call(
           ^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 332, in _with_call
    return call.result(), call
           ^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_channel.py", line 440, in result
    raise self
  File "/databricks/python/lib/python3.12/site-packages/grpc/_interceptor.py", line 315, in continuation
    response, call = self._thunk(new_method).with_call(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_channel.py", line 1198, in with_call
    return _end_unary_response_blocking(state, call, True, None)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/grpc/_channel.py", line 1006, in _end_unary_response_blocking
    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:
	status = StatusCode.INTERNAL
	details = "[INVALID_HANDLE.SESSION_CLOSED] The handle f216af12-8b5a-4081-944a-57cfc9c9fdaf is invalid. Session was closed. SQLSTATE: HY000"
	debug_error_string = "UNKNOWN:Error received from peer  {created_time:"2026-01-05T09:11:50.961327219+00:00", grpc_status:13, grpc_message:"[INVALID_HANDLE.SESSION_CLOSED] The handle f216af12-8b5a-4081-944a-57cfc9c9fdaf is invalid. Session was closed. SQLSTATE: HY000"}"
>


26/01/05 09:11:52 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:11:52 INFO ReplCrashUtils$: python shell exit code: 143; replId: ReplId-38f1a-322e1-cf9, pid: 4080
26/01/05 09:11:52 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:11:52 INFO PythonDriverWrapper: Stopping main loop for REPL ReplId-38f1a-322e1-cf9
26/01/05 09:11:52 INFO ReplManagerImpl: ReplInfo(driverReplId=ReplId-38f1a-322e1-cf9, chauffeurReplId=ReplId-38f1a-322e1-cf9,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-987305543573757)), lazyInfoInitialized=true) successfully discarded
26/01/05 09:11:52 WARN SessionUserManager$: Fail to kill all processes by user spark-dc176015-7248-4262-8bcd-d4, ret code: 1, errMsg: Cannot find user spark-dc176015-7248-4262-8bcd-d4

26/01/05 09:11:54 INFO ReplManagerImpl: REPL ReplId-38f1a-322e1-cfa finished addReplToExecutionContext (1)
26/01/05 09:11:54 INFO PythonReplFactory: Cold-start repl creation for: python, ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true)
26/01/05 09:11:54 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:11:53 +0000] "GET /metrics HTTP/1.1" 200 98316 
26/01/05 09:11:54 INFO SessionUserManager$: Successfully created a user with ID 1010 for spark-804576c7-314a-4a39-a3c5-a3.
26/01/05 09:11:54 INFO ReplOuterWrapper: DriverWrapper created for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true)
26/01/05 09:11:54 INFO ReplManagerImpl: Adding repl ReplId-38f1a-322e1-cfa to execution context session-2510101955956775-140943832011608 with Spark Connect session ID: Some(15e577cc-96c8-4dc2-b380-d60c2ba31b76) (2)
26/01/05 09:11:54 INFO ReplManagerImpl: StartReplOptions: 
26/01/05 09:11:54 INFO PythonDriverWrapper: REPL status transitioned to Starting ReplId-38f1a-322e1-cfa (3)
26/01/05 09:11:54 INFO PythonDriverWrapper: Starting ReplId-38f1a-322e1-cfa - driverStatus transitioned to Starting (4)
26/01/05 09:11:54 INFO JupyterDriverLocal: Setting up Python REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true), initializing JupyterDriverLocal (5 - 0)
26/01/05 09:11:54 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true)
26/01/05 09:11:54 INFO JupyterDriverLocal: Starting gateway server for repl ReplId-38f1a-322e1-cfa
26/01/05 09:11:54 INFO PythonPy4JUtil: Using pinned thread mode in Py4J
26/01/05 09:11:54 INFO JupyterDriverLocal: Starting Python for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true): started Py4J Gateway Server (5 - 1)
26/01/05 09:11:54 INFO VirtualenvCloneHelper: Creating Python notebook virtualenv for 804576c7-314a-4a39-a3c5-a3722f46ad9c with user spark-804576c7-314a-4a39-a3c5-a3
26/01/05 09:11:54 INFO Utils: resolved command to be run: List(/bin/su, spark-804576c7-314a-4a39-a3c5-a3, -c, virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-804576c7-314a-4a39-a3c5-a3722f46ad9c -p /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python --no-download --no-setuptools --no-wheel)
26/01/05 09:11:55 INFO PythonEnvCloneHelper$: Created python virtualenv: /local_disk0/.ephemeral_nfs/envs/pythonEnv-804576c7-314a-4a39-a3c5-a3722f46ad9c
26/01/05 09:11:55 INFO Utils: resolved command to be run: List(/bin/su, spark-804576c7-314a-4a39-a3c5-a3, -c, /local_disk0/.ephemeral_nfs/cluster_libraries/python/bin/python -c "import sys;dirs=[p for p in sys.path if 'package' in p];print('__SITE_DELIMITER__'.join([f'import site;site.addsitedir(\"\"\"{path}\"\"\")' for path in dirs]))")
26/01/05 09:11:55 INFO Utils: resolved command to be run: List(/bin/su, spark-804576c7-314a-4a39-a3c5-a3, -c, /local_disk0/.ephemeral_nfs/envs/pythonEnv-804576c7-314a-4a39-a3c5-a3722f46ad9c/bin/python -c "from sysconfig import get_path; print(get_path('purelib'))")
26/01/05 09:11:55 INFO PythonEnvCloneHelper$: Created sites.pth at /local_disk0/.ephemeral_nfs/envs/pythonEnv-804576c7-314a-4a39-a3c5-a3722f46ad9c/lib/python3.12/site-packages/sites.pth
26/01/05 09:11:55 INFO NotebookScopedPythonEnvManager: Time spent creating Python notebook virtualenv /local_disk0/.ephemeral_nfs/envs/pythonEnv-804576c7-314a-4a39-a3c5-a3722f46ad9c is 573 ms
26/01/05 09:11:55 INFO NotebookScopedPythonEnvManager: Check environment isGPU: false
26/01/05 09:11:55 INFO JupyterDriverLocal: Created Python Environment Manager for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true) (5 - 2)
26/01/05 09:11:55 INFO JupyterDriverLocal: Created LSP backend symlink for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true) (5 - 3)
26/01/05 09:11:55 INFO JupyterDriverLocal: Sandbox API is not used in REPL
26/01/05 09:11:55 INFO NotebookScopedPythonEnvManager: Registered /local_disk0/.ephemeral_nfs/envs/pythonEnv-804576c7-314a-4a39-a3c5-a3722f46ad9c/lib/python3.12/site-packages with the WatchService sun.nio.fs.LinuxWatchService$LinuxWatchKey@5630fae9 (5 current watcher(s)).
26/01/05 09:11:55 INFO IpykernelUtils$: Python process builder: [bash, /local_disk0/.ephemeral_nfs/envs/pythonEnv-804576c7-314a-4a39-a3c5-a3722f46ad9c/python_start_notebook_scoped.sh, /databricks/spark/python/pyspark/wrapped_python.py, spark-804576c7-314a-4a39-a3c5-a3, /local_disk0/.ephemeral_nfs/envs/pythonEnv-804576c7-314a-4a39-a3c5-a3722f46ad9c/bin/python, /databricks/python_shell/scripts/db_ipykernel_launcher.py, -f, /databricks/kernel-connections/105785c1d512f969aea0b54e6cb0230f5054895237db7945031d9e1fe8a9330d.json]
26/01/05 09:11:55 INFO IpykernelUtils$: Established and started ipyKernelProcess for REPL ReplId-38f1a-322e1-cfa (5 - 4)
26/01/05 09:11:55 INFO IpykernelUtils$: Cgroup isolation disabled, not placing python process with ReplId=ReplId-38f1a-322e1-cfa in repl cgroup
26/01/05 09:11:55 INFO IpykernelUtils$: Configured ipykernel stdout and stdin (5 - 5)
26/01/05 09:11:56 INFO IpykernelUtils$: Connection file updated for REPL ReplId-38f1a-322e1-cfa (5 - 6)
26/01/05 09:11:56 INFO JupyterDriverLocal: iPykernel process started and configured for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true) (5 - 7)
26/01/05 09:11:56 INFO JupyterDriverLocal: Jupyter client and comm channels configured for repl ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true) (5 - 8)
26/01/05 09:11:56 INFO JupyterDriverLocal: Watchdog thread started for repl ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true) (5 - 9)
26/01/05 09:11:57 INFO JupyterDriverLocal: JupyterKernelListener instantiated and started for REPL ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true) (5 - 10)
26/01/05 09:11:57 INFO PythonDriverWrapper: Driver instantiated for ReplId-38f1a-322e1-cfa (6)
26/01/05 09:11:57 INFO NotebookScopedPythonEnvManager: Pip metadata is empty, cleanup old pip configuration if exists
26/01/05 09:11:57 INFO PythonDriverWrapper: REPL started but is idle: ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true) (7)
26/01/05 09:11:57 INFO PythonDriverWrapper: setupRepl:ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true): finished to load
26/01/05 09:11:57 INFO PythonDriverWrapper: Finished setting-up REPL ReplId-38f1a-322e1-cfa, accepting commands (8)
26/01/05 09:11:57 INFO ProgressReporter$: Added result fetcher for 1001767603936506_5521935260654010586_run-140943832011608-ec-session-2510101955956775-140943832011608-list-libraries
26/01/05 09:11:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:11:57 WARN WsfsHttpClient: Host http://databricks.node.host.local does not exist: java.net.UnknownHostException: databricks.node.host.local: Name or service not known
26/01/05 09:11:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:11:57 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:11:57 WARN JupyterKernelListener: Results buffer should be empty before command run but it is:
--start--
AnsiResult(Mon Jan  5 09:11:56 2026 Connection to spark from PID  4391
Mon Jan  5 09:11:56 2026 Initialized gateway on port 35623
Mon Jan  5 09:11:56 2026 Connected to spark.
,Some(stderr),Map(),Map(),List(),List(),Map())
--end--

Disregarding messages.

26/01/05 09:11:57 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_5521935260654010586_run-140943832011608-ec-session-2510101955956775-140943832011608-list-libraries
26/01/05 09:11:57 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_5521935260654010586_run-140943832011608-ec-session-2510101955956775-140943832011608-list-libraries
26/01/05 09:11:57 INFO ProgressReporter$: Added result fetcher for 1001767603936506_6925224689936617834_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:11:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:11:57 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:01 INFO MemoryUsageTracker: GC notification:
 Name: PS Scavenge,
 Action: end of minor GC,
 Cause: Allocation Failure
 StartTime: 458766
 Duration: 36
26/01/05 09:12:04 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_6925224689936617834_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:04 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_6925224689936617834_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:04 INFO ProgressReporter$: Added result fetcher for 1001767603936506_8245938655194658675_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:04 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:04 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:04 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_8245938655194658675_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:04 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_8245938655194658675_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:04 INFO ProgressReporter$: Added result fetcher for 1001767603936506_7752116249040006060_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:04 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:04 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:07 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_7752116249040006060_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:07 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_7752116249040006060_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:07 INFO ProgressReporter$: Added result fetcher for 1001767603936506_5237430844101148178_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:07 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:07 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:08 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_5237430844101148178_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:08 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_5237430844101148178_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:08 INFO ProgressReporter$: Added result fetcher for 1001767603936506_6091196725472804406_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:08 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:08 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:10 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_6091196725472804406_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:10 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_6091196725472804406_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:10 INFO ProgressReporter$: Added result fetcher for 1001767603936506_6223266814065366772_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:10 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:10 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:10 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_6223266814065366772_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:10 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_6223266814065366772_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:10 INFO ProgressReporter$: Added result fetcher for 1001767603936506_6910978254745626359_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:10 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:10 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:11 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_6910978254745626359_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:11 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_6910978254745626359_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:11 INFO ProgressReporter$: Added result fetcher for 1001767603936506_7633045835940487289_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:11 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:11 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:12 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_7633045835940487289_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:12 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_7633045835940487289_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:12 INFO ProgressReporter$: Added result fetcher for 1001767603936506_6699221817272613451_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:12 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:12 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:12 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_6699221817272613451_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:12 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_6699221817272613451_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:12 INFO ProgressReporter$: Added result fetcher for 1001767603936506_5073262333263114299_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:12 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:12 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:13 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_5073262333263114299_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:13 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_5073262333263114299_org-2510101955956775-job-359180529947007-run-140943832011608-action-620488104694780
26/01/05 09:12:13 INFO ProgressReporter$: Added result fetcher for 1001767603936506_8726109649977294230_run-140943832011608-ec-session-2510101955956775-140943832011608-retreive-library-info
26/01/05 09:12:13 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:13 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:13 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:12:13 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_8726109649977294230_run-140943832011608-ec-session-2510101955956775-140943832011608-retreive-library-info
26/01/05 09:12:13 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_8726109649977294230_run-140943832011608-ec-session-2510101955956775-140943832011608-retreive-library-info
26/01/05 09:12:16 INFO ProgressReporter$: Added result fetcher for 1001767603936506_8360726235710075070_run-140943832011608-ec-session-2510101955956775-140943832011608-retrieve-dbr-runtime-info
26/01/05 09:12:16 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:16 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:16 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:12:16 INFO RequestLogging: 127.0.0.1 - - [05/Jan/2026:09:12:16 +0000] "GET /metrics HTTP/1.1" 200 98991 
26/01/05 09:12:17 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_8360726235710075070_run-140943832011608-ec-session-2510101955956775-140943832011608-retrieve-dbr-runtime-info
26/01/05 09:12:17 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_8360726235710075070_run-140943832011608-ec-session-2510101955956775-140943832011608-retrieve-dbr-runtime-info
26/01/05 09:12:19 INFO ProgressReporter$: Added result fetcher for 1001767603936506_8541757980347583256_run-140943832011608-ec-session-2510101955956775-140943832011608-release-spark-session
26/01/05 09:12:19 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:19 INFO LocalFuseProcess: Time namespace for current process (registered process pid=4391): time:[4026531834]
26/01/05 09:12:19 WARN JupyterDriverLocal: The context seems empty, likely executing non-notebook command, not setting sys.path
26/01/05 09:12:19 INFO ProgressReporter$: Removed result fetcher for 1001767603936506_8541757980347583256_run-140943832011608-ec-session-2510101955956775-140943832011608-release-spark-session
26/01/05 09:12:19 INFO ServerlessStreamingQueryTracker: Command execution complete on Driver, no active Streaming query runs associated with command 1001767603936506_8541757980347583256_run-140943832011608-ec-session-2510101955956775-140943832011608-release-spark-session
26/01/05 09:12:22 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:12:22 INFO PythonDriverLocalBase$RedirectThread: Python RedirectThread exit
26/01/05 09:12:22 INFO ReplCrashUtils$: python shell exit code: 143; replId: ReplId-38f1a-322e1-cfa, pid: 4391
26/01/05 09:12:22 INFO PythonDriverWrapper: Stopping main loop for REPL ReplId-38f1a-322e1-cfa
26/01/05 09:12:22 INFO ReplManagerImpl: ReplInfo(driverReplId=ReplId-38f1a-322e1-cfa, chauffeurReplId=ReplId-38f1a-322e1-cfa,
 executionContextId=Some(ExecutionContextIdV2(session-2510101955956775-140943832011608)), lazyInfoInitialized=true) successfully discarded
26/01/05 09:12:23 WARN SessionUserManager$: Fail to kill all processes by user spark-804576c7-314a-4a39-a3c5-a3, ret code: 1, errMsg: Cannot find user spark-804576c7-314a-4a39-a3c5-a3

